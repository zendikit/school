
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Zendikit educational material">
      
      
        <meta name="author" content="Zendikit">
      
      
        <link rel="canonical" href="https://zendikit.school/computer_vision/learned/engine/datasets/">
      
      <link rel="icon" href="../../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.3.0, mkdocs-material-8.3.9">
    
    
      
        <title>Datasets - Zendikit School</title>
      
    
    
      <link rel="stylesheet" href="../../../../assets/stylesheets/main.1d29e8d0.min.css">
      
        
        <link rel="stylesheet" href="../../../../assets/stylesheets/palette.cbb835fc.min.css">
        
          
          
          <meta name="theme-color" content="#ffffff">
        
      
      
    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../../../..",location),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="white" data-md-color-accent="">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#datasets" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../../.." title="Zendikit School" class="md-header__button md-logo" aria-label="Zendikit School" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Zendikit School
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Datasets
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../.." title="Zendikit School" class="md-nav__button md-logo" aria-label="Zendikit School" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    Zendikit School
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../../.." class="md-nav__link">
        Home
      </a>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2" type="checkbox" id="__nav_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_2">
          Japanese
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Japanese" data-md-level="1">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          Japanese
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2_1" type="checkbox" id="__nav_2_1" >
      
      
      
      
        <label class="md-nav__link" for="__nav_2_1">
          Grammar
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Grammar" data-md-level="2">
        <label class="md-nav__title" for="__nav_2_1">
          <span class="md-nav__icon md-icon"></span>
          Grammar
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../japanese/grammar/introduction/" class="md-nav__link">
        Introduction
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../japanese/grammar/n5/" class="md-nav__link">
        N5
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../japanese/grammar/n4/" class="md-nav__link">
        N4
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3" type="checkbox" id="__nav_3" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_3">
          Computer Vision
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Computer Vision" data-md-level="1">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          Computer Vision
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3_1" type="checkbox" id="__nav_3_1" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_3_1">
          Learned
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Learned" data-md-level="2">
        <label class="md-nav__title" for="__nav_3_1">
          <span class="md-nav__icon md-icon"></span>
          Learned
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../introduction/" class="md-nav__link">
        Introduction
      </a>
    </li>
  

            
          
            
              
  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3_1_2" type="checkbox" id="__nav_3_1_2" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_3_1_2">
          Engine
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Engine" data-md-level="3">
        <label class="md-nav__title" for="__nav_3_1_2">
          <span class="md-nav__icon md-icon"></span>
          Engine
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../skeleton/" class="md-nav__link">
        Skeleton
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../skeleton_implementation/" class="md-nav__link">
        Skeleton Implementation
      </a>
    </li>
  

            
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          Datasets
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        Datasets
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#our-first-dataset" class="md-nav__link">
    Our First Dataset
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#dataset-splits" class="md-nav__link">
    Dataset Splits
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#engine-interface" class="md-nav__link">
    Engine Interface
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#challenge" class="md-nav__link">
    Challenge
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../dataset_implementation/" class="md-nav__link">
        Dataset Implementation
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../dataset_visualization/" class="md-nav__link">
        Dataset Visualization
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../dataset_visualization_implementation/" class="md-nav__link">
        Dataset Visualization Implementation
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#our-first-dataset" class="md-nav__link">
    Our First Dataset
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#dataset-splits" class="md-nav__link">
    Dataset Splits
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#engine-interface" class="md-nav__link">
    Engine Interface
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#challenge" class="md-nav__link">
    Challenge
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                


<h1 id="datasets">Datasets</h1>
<p>Just as with deep learning in general, at the core of training a model for
computer vision tasks is lots of data. The tunable parts of our models are
called parameters. Parameters are simply numerical values in tensors that
participate in the math done in the algorithm.</p>
<p>In rule-based algorithms, humans tune the algorithms based on intuition (the
side of a car has a shape that looks like <em>this</em> and the front a shape that
looks like <em>that</em>) and small-scale feedback loops (we found we can identify cars
with their doors closed, but we forgot about cars with their doors open, so we
need to add a case for those). The fundamental parts that something like a car
is decomposed into in an image are called features. In rule-based algorithms,
features are hand-selected and hand-tuned.</p>
<p>Imaging trying to come up with a list of criteria for what constitutes a car.
Now image a car that somehow is not captured by those criteria. If you think
you've found a list of criteria that describes a majority of cars, now consider
how you'd code that criteria. This has proven to be impractical for humans.</p>
<p>In learned computer vision, the machine not only tunes the algorithm but also
discovers the features. These features are hardly intuitive to humans; for now
it's sufficient to say (going with the car example) that they are mathematical
relationships between some weighted combination of every instance of a car that
our model has seen in training. If we are training our model from scratch, then
before the first iteration, it has never "seen" a car before, unlike a human who
has likely seen cars everyday for years if not decades. In order for our model
to generalize well, we need to show it very many cars.</p>
<p>This is where the <em>dataset</em> comes into play. A dataset in our context is a
collection of training data and annotations. Following our example of cars, the
training data could be images with (and without!) cars in them. We would provide
these to our model and "ask" it to identify all cars in some image. The
annotations (or <em>ground truth</em>, or <em>targets</em>) are metadata about each image. The
metadata might contain information such as the regions of an image occupied by
cars. We compare what the annotations say about an image with what our model
says about the same image to determine how well our model performed its <em>tasks</em>
on that image. Things such as classification (<em>what</em> is this an image of--a car,
a person, a tree?), detection (<em>where</em> are the cars in this image?), and
segmentation (does this pixel belong to a car, a road, a tree, or maybe
something else?) are examples of tasks.</p>
<p>Datasets are typically created around certain subject matter and for specific
tasks. For example, the <a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-10</a>
dataset features 10 classes of objects (animals, boats, vehicles) with 6,000
images per class. <a href="http://yann.lecun.com/exdb/mnist/">MNIST</a> contains 70,000
images of hand-written digits 0-9. <a href="https://image-net.org/index">ImageNet</a>
contains 1000 classes of general objects and over 1 million training images. The
<a href="https://waymo.com/open/">Waymo Open Dataset</a> is focused on autonomous driving
and contains <em>scenes</em> (consecutive images taken while driving, essentially
video) of autonomous driving captured by multiple sensors (cameras,
<a href="https://en.wikipedia.org/wiki/Lidar">Lidar</a>) with annotations for detection and
segmentation of vehicles, pedestrians, roads, etc. The featurefulness of this
dataset is updated over time.</p>
<p>As suggested before, to generalize well, we need lots of data. That, coupled
with the representation of the data (for example, possibly very large images)
makes some datasets very large. MNIST is approximately 10 MB, CIFAR-10 about 160
MB, ImageNet is about 150 GB, and the Waymo Open Dataset is over 300 GB.</p>
<h2 id="our-first-dataset">Our First Dataset</h2>
<p>Our first dataset will be <a href="https://github.com/fastai/imagenette">imagenette</a>, a
subset of the ImageNet dataset. Imagenette contains only 10 classes. We'll use
the version containing full-size images which is 1.5 GB, compressed. If you'd
like to follow along, download that dataset now. The latest commit at the time
of our download was
<a href="https://github.com/fastai/imagenette/commit/6d5d92efc959918fcdb90e149e20d3198dfa34a8">6d5d92e</a>.
When extracted, you'll see the following directory structure:</p>
<div class="highlight"><pre><span></span><code>imagenette2
├── noisy_imagenette.csv
├── train
│   ├── n01440764
│   │   ├── ILSVRC2012_val_00000293.JPEG
│   │   └── ...
│   └── ...
└── val
    ├── n01440764
    └── ...
</code></pre></div>
<p><code>noisy_imagenette.csv</code> contains the dataset annotations and associates each
annotation with a single JPEG image. The dataset README explains the meaning of
the CSV header, but we'll clarify some details here. First, values such as
<code>n01440764</code> are class names. All images of class <code>n01440764</code> are stored in
folder <code>n01440764</code>. Second, the full form of the <code>is_valid</code> header field is
<code>is_validation</code>. <code>val</code> in the file tree also indicates <code>validation</code>. To
understand this, we need to briefly discuss dataset <em>splits</em>.</p>
<h2 id="dataset-splits">Dataset Splits</h2>
<p>So far, we've discussed data used for <em>training</em> our model, but how do we
benchmark our model to see how well it performs its tasks? We <strong>cannot</strong> use our
training data. The model may have <em>memorized</em> any image it has already seen from
the training dataset. Here, memorized means that the model encodes information
about a specific input it has seen that allows it to perform its tasks on that
particular input very well, if not perfectly. In other words, the model may have
a bias toward that input, and its performance on that input is not
representative of its general performance.</p>
<p>We need to keep the data we use for validation (or <em>testing</em>, <em>evaluation</em>,
<em>benchmarking</em>, etc.) separate from the data we use for training. One way to do
this is with a <em>train/validation split</em>. In the case of imagenette, that split
is 70/30 at the time of this writing, meaning that 70% of the data is provided
for training and 30% is reserved for validation. The validation data lives in
the <code>val</code> folder in imagenette and is marked with <code>True</code> in the <code>is_valid</code>
column of <code>noisy_imagenette.csv</code>.</p>
<p>When it comes time to test the model's performance, we put the model into a mode
that prevents it from learning and then run some data from the validation split
through the model. This way, we test the model with data is has never seen
before, and we prevent it from adjusting its tuning based on the data we just
showed it.</p>
<h2 id="engine-interface">Engine Interface</h2>
<p>We've discussed the dataset as it lives on disk. Now, let's briefly cover how we
interface with the dataset in Python. Because datasets can be very large, much
larger than available system RAM, a common practice is to build an <em>index</em> of
the data on disk at runtime. That is, we don't load all of the data into RAM at
once. Rather, we learn where the data lives on disk and load only what we need
on-demand.</p>
<p>At runtime, we learn about the dataset typically by loading one or more files
describing the dataset. In the case of imagenette, we only need to parse a
single file, <code>noisy_imagenette.csv</code>.</p>
<p>As a dataset is just a collection of items, let's have ours implement the Python
object model's
<a href="https://docs.python.org/3/glossary.html#term-sequence"><code>sequence</code> interface</a>.
This way our users can fetch samples from our dataset conveniently, such as by</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Get the ith sample.</span>
<span class="n">the_dataset</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

<span class="c1"># Iterate through the dataset.</span>
<span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="n">the_dataset</span><span class="p">:</span>
    <span class="o">...</span>
<span class="c1"># Alternatively:</span>
<span class="nb">iter</span><span class="p">(</span><span class="n">the_dataset</span><span class="p">)</span>

<span class="c1"># Get the total number of samples in the dataset.</span>
<span class="nb">len</span><span class="p">(</span><span class="n">the_dataset</span><span class="p">)</span>
</code></pre></div>
<p>What does <code>the_dataset[i]</code> return, though? The examples of datasets listed above
are enough to demonstrate that there is no shared interface between data from
different datasets. However, each dataset in the examples above do provide the
same thing conceptually: data to be input to a model and annotations containing
the ground truth corresponding to the model input. <code>the_dataset[i]</code> can thus
return a dictionary containing</p>
<div class="highlight"><pre><span></span><code><span class="p">{</span>
    <span class="s2">&quot;inputs&quot;</span><span class="p">:</span> <span class="n">loaded_images</span><span class="p">,</span>
    <span class="s2">&quot;targets&quot;</span><span class="p">:</span> <span class="n">loaded_annotations</span><span class="p">,</span>
<span class="p">}</span>
</code></pre></div>
<p>The type of <code>loaded_images</code> and <code>loaded_annotations</code> depends on the dataset. For
computer vision, <code>loaded_images</code> will typically be one or more images stored as
tensors in a list or dictionary, or the images might be batched into a single
tensor. <code>loaded_annotations</code> is often a dictionary. We'll cover these
representations in more detail in later material.</p>
<p>For now, for imagenette, let's use the following interface</p>
<div class="highlight"><pre><span></span><code><span class="p">{</span>
    <span class="s2">&quot;inputs&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="c1"># An image loaded from disk.</span>
    <span class="s2">&quot;targets&quot;</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="c1"># The class name corresponding to the loaded image.</span>
<span class="p">}</span>
</code></pre></div>
<p>We'll need to change this interface when we develop our first model, but we
don't understand why yet, so we will return to this later.</p>
<h2 id="challenge">Challenge</h2>
<p>Implement an imagenette dataset for our engine. So far, we've used the term
"dataset" to describe an archive we downloaded and stored on disk; however,
we'll also call whatever instance we create at runtime to get at the data on
disk a dataset.</p>
<p>In particular:</p>
<ol>
<li>Extend our single JSON configuration file to specify the dataset to load.</li>
<li>Extend our dataset factory to create an instance of the requested dataset.</li>
<li>Have your dataset implement Python's
   <a href="https://docs.python.org/3/glossary.html#term-sequence"><code>sequence</code> interface</a>.</li>
<li>Have your dataset return samples conforming to our interface in <em>Engine
   Interface</em>.</li>
</ol>
<p>Hints:</p>
<p>There are many ways to load an image from disk and store it as a Torch tensor.
If you're using the environment this material is created in, we already have
access to <code>numpy</code>, <code>torch</code>, <code>torchvision</code>, and <code>PIL</code>
(<a href="https://pillow.readthedocs.io/en/stable/"><code>pillow</code></a>). No one of these things
can load from disk directly to a Torch tensor by itself.</p>
<p>For imagenette, class names such as <code>n01440764</code> are not very human-friendly. You
can find a friendlier mapping
<a href="https://docs.fast.ai/tutorial.imagenette.html">here</a>.</p>
<p>We will change <code>engine/datasets.py</code> into a directory, <code>engine/datasets/</code>, so
that we can store our dataset implementations in their own files.</p>
<p>Lastly, we will instantiate two datasets, one for training data and one for
validation data.</p>

              
            </article>
            
          </div>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
    
    <nav class="md-footer__inner md-grid" aria-label="Footer" >
      
        
        <a href="../skeleton_implementation/" class="md-footer__link md-footer__link--prev" aria-label="Previous: Skeleton Implementation" rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Previous
              </span>
              Skeleton Implementation
            </div>
          </div>
        </a>
      
      
        
        <a href="../dataset_implementation/" class="md-footer__link md-footer__link--next" aria-label="Next: Dataset Implementation" rel="next">
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Next
              </span>
              Dataset Implementation
            </div>
          </div>
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg>
          </div>
        </a>
      
    </nav>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
      
      
    
    <a href="https://zendikit.work" target="_blank" rel="noopener" title="zendikit.work" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.1.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M40 32c13.25 0 24 10.75 24 24v400c0 13.3-10.75 24-24 24H24c-13.25 0-24-10.7-24-24V56c0-13.25 10.75-24 24-24h16zm88 16v416c0 8.8-7.2 16-16 16s-16-7.2-16-16V48c0-8.84 7.2-16 16-16s16 7.16 16 16zm72-16c13.3 0 24 10.75 24 24v400c0 13.3-10.7 24-24 24h-16c-13.3 0-24-10.7-24-24V56c0-13.25 10.7-24 24-24h16zm96 0c13.3 0 24 10.75 24 24v400c0 13.3-10.7 24-24 24h-16c-13.3 0-24-10.7-24-24V56c0-13.25 10.7-24 24-24h16zm152 24c0-13.25 10.7-24 24-24h16c13.3 0 24 10.75 24 24v400c0 13.3-10.7 24-24 24h-16c-13.3 0-24-10.7-24-24V56zm-64-8c0-8.84 7.2-16 16-16s16 7.16 16 16v416c0 8.8-7.2 16-16 16s-16-7.2-16-16V48z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": "../../../..", "features": [], "search": "../../../../assets/javascripts/workers/search.b97dbffb.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version.title": "Select version"}}</script>
    
    
      <script src="../../../../assets/javascripts/bundle.6c7ad80a.min.js"></script>
      
    
  </body>
</html>