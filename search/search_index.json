{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Zendikit School Education is an investment in the betterment of the present and future of the human condition. We take no money from you, and in return we confer no degree. We are interested only in growing skills backed by deep understanding. All material is project-based where practical. Participation requires that you are self-directed, have a computer, and have internet access.","title":"Home"},{"location":"#zendikit-school","text":"Education is an investment in the betterment of the present and future of the human condition. We take no money from you, and in return we confer no degree. We are interested only in growing skills backed by deep understanding. All material is project-based where practical. Participation requires that you are self-directed, have a computer, and have internet access.","title":"Zendikit School"},{"location":"computer_vision/learned/introduction/","text":"Learned Computer Vision Learned computer vision differs from rule-based computer vision in that the tuning of vision algorithms is done automatically by the machine instead of by humans. In literature and elsewhere in this material, you will see machine-tuned algorithms called \"learned algorithms\" although a human still typically outlines the general algorithm. An algorithm for performing a computer vision task subjected to learning is called a model, and a learned algorithm is called a learned model or often also just \"model.\" The material here will have us build an engine to develop models and then the models themselves. We'll do everything from scratch where reasonable. Examples of things we consider unreasonable in this scope are reimplementing tensor libraries and manually taking the gradient of our algorithms. Knowing how to do both is valuable, but the former is an exercise in high-performance computing and the latter becomes impractical as our algorithms grow in complexity. Prerequisites This material is developed on a Linux-based machine with a modern, discrete Nvidia GPU. You can use other operating systems, other types of GPUs, and CPU-only machines, but our examples may not run directly on your environment. For software, we'll do everything in Python 3, and our major dependencies will include numpy , pytorch , and virtualenv . Environment Setup You can recreate the environment this material is created in via git clone git@github.com:zendikit/school.git cd wherever/you/want/your/code pip3 install --user virtualenv virtualenv --python python3.8 learned cd learned source ./bin/activate ZENDIKIT_PATH=path_to_zendikit_school/material/computer_vision/learned pip3 install -r $ZENDIKIT_PATH/requirements.txt","title":"Introduction"},{"location":"computer_vision/learned/introduction/#learned-computer-vision","text":"Learned computer vision differs from rule-based computer vision in that the tuning of vision algorithms is done automatically by the machine instead of by humans. In literature and elsewhere in this material, you will see machine-tuned algorithms called \"learned algorithms\" although a human still typically outlines the general algorithm. An algorithm for performing a computer vision task subjected to learning is called a model, and a learned algorithm is called a learned model or often also just \"model.\" The material here will have us build an engine to develop models and then the models themselves. We'll do everything from scratch where reasonable. Examples of things we consider unreasonable in this scope are reimplementing tensor libraries and manually taking the gradient of our algorithms. Knowing how to do both is valuable, but the former is an exercise in high-performance computing and the latter becomes impractical as our algorithms grow in complexity.","title":"Learned Computer Vision"},{"location":"computer_vision/learned/introduction/#prerequisites","text":"This material is developed on a Linux-based machine with a modern, discrete Nvidia GPU. You can use other operating systems, other types of GPUs, and CPU-only machines, but our examples may not run directly on your environment. For software, we'll do everything in Python 3, and our major dependencies will include numpy , pytorch , and virtualenv .","title":"Prerequisites"},{"location":"computer_vision/learned/introduction/#environment-setup","text":"You can recreate the environment this material is created in via git clone git@github.com:zendikit/school.git cd wherever/you/want/your/code pip3 install --user virtualenv virtualenv --python python3.8 learned cd learned source ./bin/activate ZENDIKIT_PATH=path_to_zendikit_school/material/computer_vision/learned pip3 install -r $ZENDIKIT_PATH/requirements.txt","title":"Environment Setup"},{"location":"computer_vision/learned/engine/dataset_implementation/","text":"Dataset Implementation trainer.py Below are our changes to our trainer. # ... from engine.configuration import load_config from engine.datasets.factory import load_dataset from engine.models import build_model def main (): # ... config = load_config ( args . config ) training_dataset = load_dataset ( config , training = True ) validation_dataset = load_dataset ( config , training = False ) model = build_model () # ... We now import load_dataset from engine.datasets.factory.py . Also, we instantiate both a training_dataset and validation_dataset . We pass the config into load_dataset since the configuration contains not only the name of the dataset we want to load but also additional values the dataset instance itself will need. load_dataset also features a training parameter that we use to indicate whether we want to load training data or validation data. factory.py factory.py looks as follows. from collections.abc import Sequence from typing import Dict from engine.datasets.imagenette import Imagenette def load_dataset ( config : Dict , training : bool ) -> Sequence : \"\"\" Load a dataset. @p config A configuration dictionary. The nested key `dataset.name` is required. @p training If True, load only training data; else only validation data. @return An instance of a loaded dataset. @exception ValueError `name` doesn't name a known dataset. \"\"\" name = config [ \"dataset\" ][ \"name\" ] if name == Imagenette . __name__ : return Imagenette ( config , training ) raise ValueError ( f \" { name } doesn't name a known dataset\" ) In the documentation, we declare the required keys in the configuration. This practice is important because config is otherwise opaque--we don't know which keys and values it has, and our users won't know which we require unless we document our expectations. load_dataset expects that all datasets implement the collections.abc.Sequence interface, so we have load_dataset declare that it simply returns something you can iterate over. Also, we compare name == Imagenette.__name__ instead of comparing name == \"Imagenette\" because, were someone to refactor Imagenette and change its name, the condition here will always check against the class name proper and not a potentially out-of-date string. stub_config.json Our configuration now looks as follows. { \"dataset\" : { \"name\" : \"Imagenette\" , \"path\" : \"/abs/path/to/imagenette2/noisy_imagenette.csv\" }, \"trainer\" : { \"num_iters\" : 1 } } We add a new dataset object that contains the name of the dataset, which we choose to match the name of the class we implemented, and a path to a file describing the dataset. imagenette.py Lastly, here is our implementation of engine/datasets/imagenette.py . \"\"\"Provides the imagenette2 dataset.\"\"\" import csv import os from collections.abc import Sequence from typing import Dict , List , NamedTuple , Tuple import torchvision from PIL import Image class _PathAndClass ( NamedTuple ): path : str cls : str class Imagenette ( Sequence , Visualizable ): def __init__ ( self , config : Dict , training : bool ): \"\"\" @p config A configuration dictionary. The nested key `dataset.path` is required. `dataset.path` is assumed to point to noisy_imagenette.csv. @p training If True, load only training data; else only validation data. \"\"\" csv_pathname = config [ \"dataset\" ][ \"path\" ] self . _class_remapper = { \"n01440764\" : \"tench\" , \"n02102040\" : \"english_springer\" , \"n02979186\" : \"cassette_player\" , \"n03000684\" : \"chainsaw\" , \"n03028079\" : \"church\" , \"n03394916\" : \"french_horn\" , \"n03417042\" : \"garbage_truck\" , \"n03425413\" : \"gas_pump\" , \"n03445777\" : \"golf_ball\" , \"n03888257\" : \"parachute\" , } self . _data : List [ _PathAndClass ] = [] self . _to_tensor = torchvision . transforms . ToTensor () # Build the dataset index. with open ( csv_pathname , \"r\" ) as f : # Indices into a row in the CSV file. img_path_idx = 0 class_idx = 1 valid_idx = 6 base_dir = os . path . dirname ( csv_pathname ) reader = csv . reader ( f ) next ( reader ) # Skip the first (header) row. for row in reader : is_valid = row [ valid_idx ] == \"True\" # Skip samples that don't match our dataset type (train/valid). if training and is_valid or not training and not is_valid : continue img_path = os . path . join ( base_dir , row [ img_path_idx ]) img_class = row [ class_idx ] self . _data . append ( _PathAndClass ( img_path , img_class )) def __len__ ( self ) -> int : \"\"\"@return The number of samples in the dataset.\"\"\" return len ( self . _data ) def __getitem__ ( self , index : int ) -> Dict : \"\"\" @p index An index into the dataset. Positive numbers must be less than len(dataset). @return A dictionary with: \"inputs\": A torch.Tensor containing the image as (C, H, W). \"targets\": The class of the object in the `inputs` tensor. \"\"\" assert index < len ( self ), \"Positive index out of range.\" with Image . open ( self . _data [ index ] . path ) as img : img_tensor = self . _to_tensor ( img ) return { \"inputs\" : img_tensor , \"targets\" : self . _class_remapper [ self . _data [ index ] . cls ], } Let's jump right to the Imagenette implementation. As with load_dataset , we document our key and value expectations for config . We provide our class name remapper as self._class_remapper . Next, we initialize our dataset index as self._data . self._data is a list of _PathAndClass instances. _PathAndClass serves only to hold a path to an image and the class of the image in our context, and it derives from typing.NamedTuple to allow us to annotate the field names. We could use a plain tuple, but we would then be lacking the self-documenting property of a named tuple. Next we instantiate a torchvision.transforms.ToTensor . We'll discuss this more later. Finally in __init__ , we iterate through the CSV file's rows and build our dataset index. __len__ is self-explanatory. __getitem__ uses Pillow.Image to load an image from disk. We then use our aforementioned self._to_tensor Torchvision transformation to convert the Pillow image to a Torch tensor. Finally, we build the dictionary to return but remap the sample's class name before adding it to the dictionary. Testing We could imagine adding a test for Imagenette . The test might confirm the number of training and validation samples loaded, check that the first and last sample of each dataset matches what is specified in noisy_imagenette.csv , and also fetch a sample out of the datasets and confirm the returned dictionary's keys and values. This all relies on the data being available, though, which is not a big problem for us right now but quickly becomes a problem when developing an engine at scale, where we have an arbitrary number of developers contributing to the source code. We can't anticipate where each dataset we might need for tests lives on disk in the runtime without the user doing so manual work to specify it. Also, if the datasets are massive, it's unfriendly to require other developers to have to download them to run the tests. If we run our tests in a consistent, standardized environment, though, such as containerized as part of some continuous integration, then these tests become more feasible. An alternative is to create a very small subset of a large dataset and use this in testing. Locating this on an end-user's system reliably could be done by having the engine itself fetch the dataset from some networked server, for example. In our case here, we'll do a manual test only. For example, we can use the Python debugger and break somewhere in trainer.py . config = load_config ( args . config ) training_dataset = load_dataset ( config , training = True ) validation_dataset = load_dataset ( config , training = False ) breakpoint () # Stop here. model = build_model () We could then inspect the datasets in the debugger. (Pdb) p len(training_dataset) 9469 (Pdb) p len(validation_dataset) 3925 (Pdb) p training_dataset[0] {'inputs': tensor( # ... ), 'targets': 'cassette_player'} (Pdb) p training_dataset[-1] {'inputs': tensor( # ... ), 'targets': 'gas_pump'}","title":"Dataset Implementation"},{"location":"computer_vision/learned/engine/dataset_implementation/#dataset-implementation","text":"","title":"Dataset Implementation"},{"location":"computer_vision/learned/engine/dataset_implementation/#trainerpy","text":"Below are our changes to our trainer. # ... from engine.configuration import load_config from engine.datasets.factory import load_dataset from engine.models import build_model def main (): # ... config = load_config ( args . config ) training_dataset = load_dataset ( config , training = True ) validation_dataset = load_dataset ( config , training = False ) model = build_model () # ... We now import load_dataset from engine.datasets.factory.py . Also, we instantiate both a training_dataset and validation_dataset . We pass the config into load_dataset since the configuration contains not only the name of the dataset we want to load but also additional values the dataset instance itself will need. load_dataset also features a training parameter that we use to indicate whether we want to load training data or validation data.","title":"trainer.py"},{"location":"computer_vision/learned/engine/dataset_implementation/#factorypy","text":"factory.py looks as follows. from collections.abc import Sequence from typing import Dict from engine.datasets.imagenette import Imagenette def load_dataset ( config : Dict , training : bool ) -> Sequence : \"\"\" Load a dataset. @p config A configuration dictionary. The nested key `dataset.name` is required. @p training If True, load only training data; else only validation data. @return An instance of a loaded dataset. @exception ValueError `name` doesn't name a known dataset. \"\"\" name = config [ \"dataset\" ][ \"name\" ] if name == Imagenette . __name__ : return Imagenette ( config , training ) raise ValueError ( f \" { name } doesn't name a known dataset\" ) In the documentation, we declare the required keys in the configuration. This practice is important because config is otherwise opaque--we don't know which keys and values it has, and our users won't know which we require unless we document our expectations. load_dataset expects that all datasets implement the collections.abc.Sequence interface, so we have load_dataset declare that it simply returns something you can iterate over. Also, we compare name == Imagenette.__name__ instead of comparing name == \"Imagenette\" because, were someone to refactor Imagenette and change its name, the condition here will always check against the class name proper and not a potentially out-of-date string.","title":"factory.py"},{"location":"computer_vision/learned/engine/dataset_implementation/#stub_configjson","text":"Our configuration now looks as follows. { \"dataset\" : { \"name\" : \"Imagenette\" , \"path\" : \"/abs/path/to/imagenette2/noisy_imagenette.csv\" }, \"trainer\" : { \"num_iters\" : 1 } } We add a new dataset object that contains the name of the dataset, which we choose to match the name of the class we implemented, and a path to a file describing the dataset.","title":"stub_config.json"},{"location":"computer_vision/learned/engine/dataset_implementation/#imagenettepy","text":"Lastly, here is our implementation of engine/datasets/imagenette.py . \"\"\"Provides the imagenette2 dataset.\"\"\" import csv import os from collections.abc import Sequence from typing import Dict , List , NamedTuple , Tuple import torchvision from PIL import Image class _PathAndClass ( NamedTuple ): path : str cls : str class Imagenette ( Sequence , Visualizable ): def __init__ ( self , config : Dict , training : bool ): \"\"\" @p config A configuration dictionary. The nested key `dataset.path` is required. `dataset.path` is assumed to point to noisy_imagenette.csv. @p training If True, load only training data; else only validation data. \"\"\" csv_pathname = config [ \"dataset\" ][ \"path\" ] self . _class_remapper = { \"n01440764\" : \"tench\" , \"n02102040\" : \"english_springer\" , \"n02979186\" : \"cassette_player\" , \"n03000684\" : \"chainsaw\" , \"n03028079\" : \"church\" , \"n03394916\" : \"french_horn\" , \"n03417042\" : \"garbage_truck\" , \"n03425413\" : \"gas_pump\" , \"n03445777\" : \"golf_ball\" , \"n03888257\" : \"parachute\" , } self . _data : List [ _PathAndClass ] = [] self . _to_tensor = torchvision . transforms . ToTensor () # Build the dataset index. with open ( csv_pathname , \"r\" ) as f : # Indices into a row in the CSV file. img_path_idx = 0 class_idx = 1 valid_idx = 6 base_dir = os . path . dirname ( csv_pathname ) reader = csv . reader ( f ) next ( reader ) # Skip the first (header) row. for row in reader : is_valid = row [ valid_idx ] == \"True\" # Skip samples that don't match our dataset type (train/valid). if training and is_valid or not training and not is_valid : continue img_path = os . path . join ( base_dir , row [ img_path_idx ]) img_class = row [ class_idx ] self . _data . append ( _PathAndClass ( img_path , img_class )) def __len__ ( self ) -> int : \"\"\"@return The number of samples in the dataset.\"\"\" return len ( self . _data ) def __getitem__ ( self , index : int ) -> Dict : \"\"\" @p index An index into the dataset. Positive numbers must be less than len(dataset). @return A dictionary with: \"inputs\": A torch.Tensor containing the image as (C, H, W). \"targets\": The class of the object in the `inputs` tensor. \"\"\" assert index < len ( self ), \"Positive index out of range.\" with Image . open ( self . _data [ index ] . path ) as img : img_tensor = self . _to_tensor ( img ) return { \"inputs\" : img_tensor , \"targets\" : self . _class_remapper [ self . _data [ index ] . cls ], } Let's jump right to the Imagenette implementation. As with load_dataset , we document our key and value expectations for config . We provide our class name remapper as self._class_remapper . Next, we initialize our dataset index as self._data . self._data is a list of _PathAndClass instances. _PathAndClass serves only to hold a path to an image and the class of the image in our context, and it derives from typing.NamedTuple to allow us to annotate the field names. We could use a plain tuple, but we would then be lacking the self-documenting property of a named tuple. Next we instantiate a torchvision.transforms.ToTensor . We'll discuss this more later. Finally in __init__ , we iterate through the CSV file's rows and build our dataset index. __len__ is self-explanatory. __getitem__ uses Pillow.Image to load an image from disk. We then use our aforementioned self._to_tensor Torchvision transformation to convert the Pillow image to a Torch tensor. Finally, we build the dictionary to return but remap the sample's class name before adding it to the dictionary.","title":"imagenette.py"},{"location":"computer_vision/learned/engine/dataset_implementation/#testing","text":"We could imagine adding a test for Imagenette . The test might confirm the number of training and validation samples loaded, check that the first and last sample of each dataset matches what is specified in noisy_imagenette.csv , and also fetch a sample out of the datasets and confirm the returned dictionary's keys and values. This all relies on the data being available, though, which is not a big problem for us right now but quickly becomes a problem when developing an engine at scale, where we have an arbitrary number of developers contributing to the source code. We can't anticipate where each dataset we might need for tests lives on disk in the runtime without the user doing so manual work to specify it. Also, if the datasets are massive, it's unfriendly to require other developers to have to download them to run the tests. If we run our tests in a consistent, standardized environment, though, such as containerized as part of some continuous integration, then these tests become more feasible. An alternative is to create a very small subset of a large dataset and use this in testing. Locating this on an end-user's system reliably could be done by having the engine itself fetch the dataset from some networked server, for example. In our case here, we'll do a manual test only. For example, we can use the Python debugger and break somewhere in trainer.py . config = load_config ( args . config ) training_dataset = load_dataset ( config , training = True ) validation_dataset = load_dataset ( config , training = False ) breakpoint () # Stop here. model = build_model () We could then inspect the datasets in the debugger. (Pdb) p len(training_dataset) 9469 (Pdb) p len(validation_dataset) 3925 (Pdb) p training_dataset[0] {'inputs': tensor( # ... ), 'targets': 'cassette_player'} (Pdb) p training_dataset[-1] {'inputs': tensor( # ... ), 'targets': 'gas_pump'}","title":"Testing"},{"location":"computer_vision/learned/engine/dataset_visualization/","text":"Dataset Visualization With the current state of our engine and our imagenette dataset, if we want to view a sample in Python, we are presented with the image as a tensor and the class as a string name. The class name is clear to humans, but the image-as-a-tensor is unfriendly when trying to understand what the image looks like. For this purpose, it is helpful to implement a sample visualizer. In our case, we'll build a visualizer that displays images from a dataset one sample at a time. We'll do this in a new tool called visualizer.py that lives next to trainer.py . We'll make visualizer.py dataset-agnostic similar to trainer.py . To do this, our visualizer tool will expect that datasets implement a method that takes a sample index and returns an image that can be shown in an image viewer and a string that can be printed elsewhere, for example in the console. Challenge Implement a sample visualizer. Hints: There are a variety of Python packages that can display images. Examples are PIL , matplotlib , and OpenCV . We will use OpenCV because it also provides mechanisms to wait for key presses from the user, allowing the user to have more control over stepping through samples. We will place library code in engine/visualizer.py .","title":"Dataset Visualization"},{"location":"computer_vision/learned/engine/dataset_visualization/#dataset-visualization","text":"With the current state of our engine and our imagenette dataset, if we want to view a sample in Python, we are presented with the image as a tensor and the class as a string name. The class name is clear to humans, but the image-as-a-tensor is unfriendly when trying to understand what the image looks like. For this purpose, it is helpful to implement a sample visualizer. In our case, we'll build a visualizer that displays images from a dataset one sample at a time. We'll do this in a new tool called visualizer.py that lives next to trainer.py . We'll make visualizer.py dataset-agnostic similar to trainer.py . To do this, our visualizer tool will expect that datasets implement a method that takes a sample index and returns an image that can be shown in an image viewer and a string that can be printed elsewhere, for example in the console.","title":"Dataset Visualization"},{"location":"computer_vision/learned/engine/dataset_visualization/#challenge","text":"Implement a sample visualizer. Hints: There are a variety of Python packages that can display images. Examples are PIL , matplotlib , and OpenCV . We will use OpenCV because it also provides mechanisms to wait for key presses from the user, allowing the user to have more control over stepping through samples. We will place library code in engine/visualizer.py .","title":"Challenge"},{"location":"computer_vision/learned/engine/dataset_visualization_implementation/","text":"Dataset Visualization Implementation visualizer.py The source for our visualizer tool looks as follows. \"\"\"A dataset visualizer. Press ESC in the rendered window stop visualizing.\"\"\" import argparse import cv2 as cv from engine.configuration import load_config from engine.datasets.factory import load_dataset from engine.visualizer import Visualizable ESCAPE_KEYCODE = 27 def main (): parser = argparse . ArgumentParser ( description = __doc__ , formatter_class = argparse . RawDescriptionHelpFormatter , ) parser . add_argument ( \"config\" , help = \"A pathname to a JSON config file\" ) parser . add_argument ( \"validation\" , action = \"store_true\" , help = \"If set, visualize validation data. Else, training data.\" , ) args = parser . parse_args () config = load_config ( args . config ) dataset = load_dataset ( config , training = not args . validation ) assert isinstance ( dataset , Visualizable ), \"Dataset must implement Visualizable.\" cv_win_name = \"Dataset Visualizer\" window = cv . namedWindow ( cv_win_name , cv . WINDOW_NORMAL ) # Resizable. for index in range ( len ( dataset )): sample = dataset . get_visualizer_sample ( index ) print ( sample . text ) image = cv . cvtColor ( sample . image , cv . COLOR_RGB2BGR ) cv . imshow ( cv_win_name , image ) if cv . waitKey () == ESCAPE_KEYCODE : break if __name__ == \"__main__\" : main () Starting in main , we build our CLI. Different from trainer.py , we allow the user to declare whether they want to visualize the training or validation split. We then load our configuration and dataset. We require any dataset used with our tool to implement the Visualizable interface. More on this later. Next, we create an OpenCV named window which we'll dispay our samples in. Since we need to call our new method get_visualizer_sample on our datasets instead of just invoking __getitem__ , we have to loop over the length of our dataset and call the new method explicitly. We print the dataset-provided text and then render the image. We expect our image channels to be in RGB order, so we convert the coloring to BGR for OpenCV's sake. Finally, if the user types ESC in the displayed window, we stop iterating. engine/visualizer.py Here is our new library code used by datasets that are compatible with our visualizer tool. from typing import NamedTuple , Protocol , runtime_checkable import numpy as np class VisualizerSample ( NamedTuple ): \"\"\" image: An image to visualize. It must be shaped as (H, W, C), RGB. text: Text to be printed. \"\"\" image : np . ndarray text : str @runtime_checkable class Visualizable ( Protocol ): \"\"\"The interface required by our engine's visualizer.\"\"\" def get_visualizer_sample ( index : int ) -> VisualizerSample : \"\"\" @p index An index into a dataset. @return A dataset sample prepared for use in the engine's visualizer. \"\"\" raise NotImplementedError () We create a new interface, called a Protocol in Python, and use runtime_checkable to allow our visualizer tool to assert isinstance(dataset, Visualizable) , which we showed earlier. Visualizable returns a VisualizerSample which is another instance of an annotated typing.NamedTuple . VisualzerSample.image is a numpy.ndarray because OpenCV works with numpy arrays and not PyTorch tensors. Also, images in numpy are often represented as (H, W, C) , where each letter is a shorthand for height, width, and color channels respectively, so we require image to be in that format. imagenette.py Lastly, we extend engine/imagenette.py as follows. # ... from engine.visualizer import Visualizable , VisualizerSample # ... class Imagenette ( Sequence , Visualizable ): # ... def get_visualizer_sample ( self , index : int ) -> VisualizerSample : \"\"\" @p index An index into a dataset. Positive numbers must be less than len(dataset). @return A dataset sample prepared for use in the engine's visualizer. \"\"\" assert index < len ( self ), \"Positive index out of range.\" sample = self [ index ] image = sample [ \"inputs\" ] . permute ( 1 , 2 , 0 ) . numpy () text = f \"index: { index } ; class: { sample [ 'targets' ] } \" return VisualizerSample ( image , text ) Here, we use torch.permute to reorder our image tensor. It was originally (C, H, W) , so we move the channel dimension to the back. Then, we convert the tensor to a numpy array . Lastly, we build text , an informational message to be printed with our sample. It contains the sample index and the sample class. Running When we run our tool, we see samples rendered and the following in the console. Pressing any key except ESC advances the visualization to the next sample, and ESC terminates visualization. $ python3 visualizer.py configs/stub_config.json index: 0; class: cassette_player index: 1; class: cassette_player <etc.>","title":"Dataset Visualization Implementation"},{"location":"computer_vision/learned/engine/dataset_visualization_implementation/#dataset-visualization-implementation","text":"","title":"Dataset Visualization Implementation"},{"location":"computer_vision/learned/engine/dataset_visualization_implementation/#visualizerpy","text":"The source for our visualizer tool looks as follows. \"\"\"A dataset visualizer. Press ESC in the rendered window stop visualizing.\"\"\" import argparse import cv2 as cv from engine.configuration import load_config from engine.datasets.factory import load_dataset from engine.visualizer import Visualizable ESCAPE_KEYCODE = 27 def main (): parser = argparse . ArgumentParser ( description = __doc__ , formatter_class = argparse . RawDescriptionHelpFormatter , ) parser . add_argument ( \"config\" , help = \"A pathname to a JSON config file\" ) parser . add_argument ( \"validation\" , action = \"store_true\" , help = \"If set, visualize validation data. Else, training data.\" , ) args = parser . parse_args () config = load_config ( args . config ) dataset = load_dataset ( config , training = not args . validation ) assert isinstance ( dataset , Visualizable ), \"Dataset must implement Visualizable.\" cv_win_name = \"Dataset Visualizer\" window = cv . namedWindow ( cv_win_name , cv . WINDOW_NORMAL ) # Resizable. for index in range ( len ( dataset )): sample = dataset . get_visualizer_sample ( index ) print ( sample . text ) image = cv . cvtColor ( sample . image , cv . COLOR_RGB2BGR ) cv . imshow ( cv_win_name , image ) if cv . waitKey () == ESCAPE_KEYCODE : break if __name__ == \"__main__\" : main () Starting in main , we build our CLI. Different from trainer.py , we allow the user to declare whether they want to visualize the training or validation split. We then load our configuration and dataset. We require any dataset used with our tool to implement the Visualizable interface. More on this later. Next, we create an OpenCV named window which we'll dispay our samples in. Since we need to call our new method get_visualizer_sample on our datasets instead of just invoking __getitem__ , we have to loop over the length of our dataset and call the new method explicitly. We print the dataset-provided text and then render the image. We expect our image channels to be in RGB order, so we convert the coloring to BGR for OpenCV's sake. Finally, if the user types ESC in the displayed window, we stop iterating.","title":"visualizer.py"},{"location":"computer_vision/learned/engine/dataset_visualization_implementation/#enginevisualizerpy","text":"Here is our new library code used by datasets that are compatible with our visualizer tool. from typing import NamedTuple , Protocol , runtime_checkable import numpy as np class VisualizerSample ( NamedTuple ): \"\"\" image: An image to visualize. It must be shaped as (H, W, C), RGB. text: Text to be printed. \"\"\" image : np . ndarray text : str @runtime_checkable class Visualizable ( Protocol ): \"\"\"The interface required by our engine's visualizer.\"\"\" def get_visualizer_sample ( index : int ) -> VisualizerSample : \"\"\" @p index An index into a dataset. @return A dataset sample prepared for use in the engine's visualizer. \"\"\" raise NotImplementedError () We create a new interface, called a Protocol in Python, and use runtime_checkable to allow our visualizer tool to assert isinstance(dataset, Visualizable) , which we showed earlier. Visualizable returns a VisualizerSample which is another instance of an annotated typing.NamedTuple . VisualzerSample.image is a numpy.ndarray because OpenCV works with numpy arrays and not PyTorch tensors. Also, images in numpy are often represented as (H, W, C) , where each letter is a shorthand for height, width, and color channels respectively, so we require image to be in that format.","title":"engine/visualizer.py"},{"location":"computer_vision/learned/engine/dataset_visualization_implementation/#imagenettepy","text":"Lastly, we extend engine/imagenette.py as follows. # ... from engine.visualizer import Visualizable , VisualizerSample # ... class Imagenette ( Sequence , Visualizable ): # ... def get_visualizer_sample ( self , index : int ) -> VisualizerSample : \"\"\" @p index An index into a dataset. Positive numbers must be less than len(dataset). @return A dataset sample prepared for use in the engine's visualizer. \"\"\" assert index < len ( self ), \"Positive index out of range.\" sample = self [ index ] image = sample [ \"inputs\" ] . permute ( 1 , 2 , 0 ) . numpy () text = f \"index: { index } ; class: { sample [ 'targets' ] } \" return VisualizerSample ( image , text ) Here, we use torch.permute to reorder our image tensor. It was originally (C, H, W) , so we move the channel dimension to the back. Then, we convert the tensor to a numpy array . Lastly, we build text , an informational message to be printed with our sample. It contains the sample index and the sample class.","title":"imagenette.py"},{"location":"computer_vision/learned/engine/dataset_visualization_implementation/#running","text":"When we run our tool, we see samples rendered and the following in the console. Pressing any key except ESC advances the visualization to the next sample, and ESC terminates visualization. $ python3 visualizer.py configs/stub_config.json index: 0; class: cassette_player index: 1; class: cassette_player <etc.>","title":"Running"},{"location":"computer_vision/learned/engine/datasets/","text":"Datasets Just as with deep learning in general, at the core of training a model for computer vision tasks is lots of data. The tunable parts of our models are called parameters. Parameters are simply numerical values in tensors that participate in the math done in the algorithm. In rule-based algorithms, humans tune the algorithms based on intuition (the side of a car has a shape that looks like this and the front a shape that looks like that ) and small-scale feedback loops (we found we can identify cars with their doors closed, but we forgot about cars with their doors open, so we need to add a case for those). The fundamental parts that something like a car is decomposed into in an image are called features. In rule-based algorithms, features are hand-selected and hand-tuned. Imaging trying to come up with a list of criteria for what constitutes a car. Now image a car that somehow is not captured by those criteria. If you think you've found a list of criteria that describes a majority of cars, now consider how you'd code that criteria. This has proven to be impractical for humans. In learned computer vision, the machine not only tunes the algorithm but also discovers the features. These features are hardly intuitive to humans; for now it's sufficient to say (going with the car example) that they are mathematical relationships between some weighted combination of every instance of a car that our model has seen in training. If we are training our model from scratch, then before the first iteration, it has never \"seen\" a car before, unlike a human who has likely seen cars everyday for years if not decades. In order for our model to generalize well, we need to show it very many cars. This is where the dataset comes into play. A dataset in our context is a collection of training data and annotations. Following our example of cars, the training data could be images with (and without!) cars in them. We would provide these to our model and \"ask\" it to identify all cars in some image. The annotations (or ground truth , or targets ) are metadata about each image. The metadata might contain information such as the regions of an image occupied by cars. We compare what the annotations say about an image with what our model says about the same image to determine how well our model performed its tasks on that image. Things such as classification ( what is this an image of--a car, a person, a tree?), detection ( where are the cars in this image?), and segmentation (does this pixel belong to a car, a road, a tree, or maybe something else?) are examples of tasks. Datasets are typically created around certain subject matter and for specific tasks. For example, the CIFAR-10 dataset features 10 classes of objects (animals, boats, vehicles) with 6,000 images per class. MNIST contains 70,000 images of hand-written digits 0-9. ImageNet contains 1000 classes of general objects and over 1 million training images. The Waymo Open Dataset is focused on autonomous driving and contains scenes (consecutive images taken while driving, essentially video) of autonomous driving captured by multiple sensors (cameras, Lidar ) with annotations for detection and segmentation of vehicles, pedestrians, roads, etc. The featurefulness of this dataset is updated over time. As suggested before, to generalize well, we need lots of data. That, coupled with the representation of the data (for example, possibly very large images) makes some datasets very large. MNIST is approximately 10 MB, CIFAR-10 about 160 MB, ImageNet is about 150 GB, and the Waymo Open Dataset is over 300 GB. Our First Dataset Our first dataset will be imagenette , a subset of the ImageNet dataset. Imagenette contains only 10 classes. We'll use the version containing full-size images which is 1.5 GB, compressed. If you'd like to follow along, download that dataset now. The latest commit at the time of our download was 6d5d92e . When extracted, you'll see the following directory structure: imagenette2 \u251c\u2500\u2500 noisy_imagenette.csv \u251c\u2500\u2500 train \u2502 \u251c\u2500\u2500 n01440764 \u2502 \u2502 \u251c\u2500\u2500 ILSVRC2012_val_00000293.JPEG \u2502 \u2502 \u2514\u2500\u2500 ... \u2502 \u2514\u2500\u2500 ... \u2514\u2500\u2500 val \u251c\u2500\u2500 n01440764 \u2514\u2500\u2500 ... noisy_imagenette.csv contains the dataset annotations and associates each annotation with a single JPEG image. The dataset README explains the meaning of the CSV header, but we'll clarify some details here. First, values such as n01440764 are class names. All images of class n01440764 are stored in folder n01440764 . Second, the full form of the is_valid header field is is_validation . val in the file tree also indicates validation . To understand this, we need to briefly discuss dataset splits . Dataset Splits So far, we've discussed data used for training our model, but how do we benchmark our model to see how well it performs its tasks? We cannot use our training data. The model may have memorized any image it has already seen from the training dataset. Here, memorized means that the model encodes information about a specific input it has seen that allows it to perform its tasks on that particular input very well, if not perfectly. In other words, the model may have a bias toward that input, and its performance on that input is not representative of its general performance. We need to keep the data we use for validation (or testing , evaluation , benchmarking , etc.) separate from the data we use for training. One way to do this is with a train/validation split . In the case of imagenette, that split is 70/30 at the time of this writing, meaning that 70% of the data is provided for training and 30% is reserved for validation. The validation data lives in the val folder in imagenette and is marked with True in the is_valid column of noisy_imagenette.csv . When it comes time to test the model's performance, we put the model into a mode that prevents it from learning and then run some data from the validation split through the model. This way, we test the model with data is has never seen before, and we prevent it from adjusting its tuning based on the data we just showed it. Engine Interface We've discussed the dataset as it lives on disk. Now, let's briefly cover how we interface with the dataset in Python. Because datasets can be very large, much larger than available system RAM, a common practice is to build an index of the data on disk at runtime. That is, we don't load all of the data into RAM at once. Rather, we learn where the data lives on disk and load only what we need on-demand. At runtime, we learn about the dataset typically by loading one or more files describing the dataset. In the case of imagenette, we only need to parse a single file, noisy_imagenette.csv . As a dataset is just a collection of items, let's have ours implement the Python object model's sequence interface . This way our users can fetch samples from our dataset conveniently, such as by # Get the ith sample. the_dataset [ i ] # Iterate through the dataset. for sample in the_dataset : ... # Alternatively: iter ( the_dataset ) # Get the total number of samples in the dataset. len ( the_dataset ) What does the_dataset[i] return, though? The examples of datasets listed above are enough to demonstrate that there is no shared interface between data from different datasets. However, each dataset in the examples above do provide the same thing conceptually: data to be input to a model and annotations containing the ground truth corresponding to the model input. the_dataset[i] can thus return a dictionary containing { \"inputs\" : loaded_images , \"targets\" : loaded_annotations , } The type of loaded_images and loaded_annotations depends on the dataset. For computer vision, loaded_images will typically be one or more images stored as tensors in a list or dictionary, or the images might be batched into a single tensor. loaded_annotations is often a dictionary. We'll cover these representations in more detail in later material. For now, for imagenette, let's use the following interface { \"inputs\" : torch . Tensor , # An image loaded from disk. \"targets\" : str , # The class name corresponding to the loaded image. } We'll need to change this interface when we develop our first model, but we don't understand why yet, so we will return to this later. Challenge Implement an imagenette dataset for our engine. So far, we've used the term \"dataset\" to describe an archive we downloaded and stored on disk; however, we'll also call whatever instance we create at runtime to get at the data on disk a dataset. In particular: Extend our single JSON configuration file to specify the dataset to load. Extend our dataset factory to create an instance of the requested dataset. Have your dataset implement Python's sequence interface . Have your dataset return samples conforming to our interface in Engine Interface . Hints: There are many ways to load an image from disk and store it as a Torch tensor. If you're using the environment this material is created in, we already have access to numpy , torch , torchvision , and PIL ( pillow ). No one of these things can load from disk directly to a Torch tensor by itself. For imagenette, class names such as n01440764 are not very human-friendly. You can find a friendlier mapping here . We will change engine/datasets.py into a directory, engine/datasets/ , so that we can store our dataset implementations in their own files. Lastly, we will instantiate two datasets, one for training data and one for validation data.","title":"Datasets"},{"location":"computer_vision/learned/engine/datasets/#datasets","text":"Just as with deep learning in general, at the core of training a model for computer vision tasks is lots of data. The tunable parts of our models are called parameters. Parameters are simply numerical values in tensors that participate in the math done in the algorithm. In rule-based algorithms, humans tune the algorithms based on intuition (the side of a car has a shape that looks like this and the front a shape that looks like that ) and small-scale feedback loops (we found we can identify cars with their doors closed, but we forgot about cars with their doors open, so we need to add a case for those). The fundamental parts that something like a car is decomposed into in an image are called features. In rule-based algorithms, features are hand-selected and hand-tuned. Imaging trying to come up with a list of criteria for what constitutes a car. Now image a car that somehow is not captured by those criteria. If you think you've found a list of criteria that describes a majority of cars, now consider how you'd code that criteria. This has proven to be impractical for humans. In learned computer vision, the machine not only tunes the algorithm but also discovers the features. These features are hardly intuitive to humans; for now it's sufficient to say (going with the car example) that they are mathematical relationships between some weighted combination of every instance of a car that our model has seen in training. If we are training our model from scratch, then before the first iteration, it has never \"seen\" a car before, unlike a human who has likely seen cars everyday for years if not decades. In order for our model to generalize well, we need to show it very many cars. This is where the dataset comes into play. A dataset in our context is a collection of training data and annotations. Following our example of cars, the training data could be images with (and without!) cars in them. We would provide these to our model and \"ask\" it to identify all cars in some image. The annotations (or ground truth , or targets ) are metadata about each image. The metadata might contain information such as the regions of an image occupied by cars. We compare what the annotations say about an image with what our model says about the same image to determine how well our model performed its tasks on that image. Things such as classification ( what is this an image of--a car, a person, a tree?), detection ( where are the cars in this image?), and segmentation (does this pixel belong to a car, a road, a tree, or maybe something else?) are examples of tasks. Datasets are typically created around certain subject matter and for specific tasks. For example, the CIFAR-10 dataset features 10 classes of objects (animals, boats, vehicles) with 6,000 images per class. MNIST contains 70,000 images of hand-written digits 0-9. ImageNet contains 1000 classes of general objects and over 1 million training images. The Waymo Open Dataset is focused on autonomous driving and contains scenes (consecutive images taken while driving, essentially video) of autonomous driving captured by multiple sensors (cameras, Lidar ) with annotations for detection and segmentation of vehicles, pedestrians, roads, etc. The featurefulness of this dataset is updated over time. As suggested before, to generalize well, we need lots of data. That, coupled with the representation of the data (for example, possibly very large images) makes some datasets very large. MNIST is approximately 10 MB, CIFAR-10 about 160 MB, ImageNet is about 150 GB, and the Waymo Open Dataset is over 300 GB.","title":"Datasets"},{"location":"computer_vision/learned/engine/datasets/#our-first-dataset","text":"Our first dataset will be imagenette , a subset of the ImageNet dataset. Imagenette contains only 10 classes. We'll use the version containing full-size images which is 1.5 GB, compressed. If you'd like to follow along, download that dataset now. The latest commit at the time of our download was 6d5d92e . When extracted, you'll see the following directory structure: imagenette2 \u251c\u2500\u2500 noisy_imagenette.csv \u251c\u2500\u2500 train \u2502 \u251c\u2500\u2500 n01440764 \u2502 \u2502 \u251c\u2500\u2500 ILSVRC2012_val_00000293.JPEG \u2502 \u2502 \u2514\u2500\u2500 ... \u2502 \u2514\u2500\u2500 ... \u2514\u2500\u2500 val \u251c\u2500\u2500 n01440764 \u2514\u2500\u2500 ... noisy_imagenette.csv contains the dataset annotations and associates each annotation with a single JPEG image. The dataset README explains the meaning of the CSV header, but we'll clarify some details here. First, values such as n01440764 are class names. All images of class n01440764 are stored in folder n01440764 . Second, the full form of the is_valid header field is is_validation . val in the file tree also indicates validation . To understand this, we need to briefly discuss dataset splits .","title":"Our First Dataset"},{"location":"computer_vision/learned/engine/datasets/#dataset-splits","text":"So far, we've discussed data used for training our model, but how do we benchmark our model to see how well it performs its tasks? We cannot use our training data. The model may have memorized any image it has already seen from the training dataset. Here, memorized means that the model encodes information about a specific input it has seen that allows it to perform its tasks on that particular input very well, if not perfectly. In other words, the model may have a bias toward that input, and its performance on that input is not representative of its general performance. We need to keep the data we use for validation (or testing , evaluation , benchmarking , etc.) separate from the data we use for training. One way to do this is with a train/validation split . In the case of imagenette, that split is 70/30 at the time of this writing, meaning that 70% of the data is provided for training and 30% is reserved for validation. The validation data lives in the val folder in imagenette and is marked with True in the is_valid column of noisy_imagenette.csv . When it comes time to test the model's performance, we put the model into a mode that prevents it from learning and then run some data from the validation split through the model. This way, we test the model with data is has never seen before, and we prevent it from adjusting its tuning based on the data we just showed it.","title":"Dataset Splits"},{"location":"computer_vision/learned/engine/datasets/#engine-interface","text":"We've discussed the dataset as it lives on disk. Now, let's briefly cover how we interface with the dataset in Python. Because datasets can be very large, much larger than available system RAM, a common practice is to build an index of the data on disk at runtime. That is, we don't load all of the data into RAM at once. Rather, we learn where the data lives on disk and load only what we need on-demand. At runtime, we learn about the dataset typically by loading one or more files describing the dataset. In the case of imagenette, we only need to parse a single file, noisy_imagenette.csv . As a dataset is just a collection of items, let's have ours implement the Python object model's sequence interface . This way our users can fetch samples from our dataset conveniently, such as by # Get the ith sample. the_dataset [ i ] # Iterate through the dataset. for sample in the_dataset : ... # Alternatively: iter ( the_dataset ) # Get the total number of samples in the dataset. len ( the_dataset ) What does the_dataset[i] return, though? The examples of datasets listed above are enough to demonstrate that there is no shared interface between data from different datasets. However, each dataset in the examples above do provide the same thing conceptually: data to be input to a model and annotations containing the ground truth corresponding to the model input. the_dataset[i] can thus return a dictionary containing { \"inputs\" : loaded_images , \"targets\" : loaded_annotations , } The type of loaded_images and loaded_annotations depends on the dataset. For computer vision, loaded_images will typically be one or more images stored as tensors in a list or dictionary, or the images might be batched into a single tensor. loaded_annotations is often a dictionary. We'll cover these representations in more detail in later material. For now, for imagenette, let's use the following interface { \"inputs\" : torch . Tensor , # An image loaded from disk. \"targets\" : str , # The class name corresponding to the loaded image. } We'll need to change this interface when we develop our first model, but we don't understand why yet, so we will return to this later.","title":"Engine Interface"},{"location":"computer_vision/learned/engine/datasets/#challenge","text":"Implement an imagenette dataset for our engine. So far, we've used the term \"dataset\" to describe an archive we downloaded and stored on disk; however, we'll also call whatever instance we create at runtime to get at the data on disk a dataset. In particular: Extend our single JSON configuration file to specify the dataset to load. Extend our dataset factory to create an instance of the requested dataset. Have your dataset implement Python's sequence interface . Have your dataset return samples conforming to our interface in Engine Interface . Hints: There are many ways to load an image from disk and store it as a Torch tensor. If you're using the environment this material is created in, we already have access to numpy , torch , torchvision , and PIL ( pillow ). No one of these things can load from disk directly to a Torch tensor by itself. For imagenette, class names such as n01440764 are not very human-friendly. You can find a friendlier mapping here . We will change engine/datasets.py into a directory, engine/datasets/ , so that we can store our dataset implementations in their own files. Lastly, we will instantiate two datasets, one for training data and one for validation data.","title":"Challenge"},{"location":"computer_vision/learned/engine/skeleton/","text":"Engine Skeleton The \"engine\" is what we'll call the software that facilitates \"training.\" Training \"Training\" is the process of iteratively tuning a model. The core steps in training are Get some data (such as images) from a dataset. Run the data through our model. Adjust our model. Repeat until we're satisfied. These steps describe what is called the \"training loop.\" Let's codify it and start building our engine skeleton. # Training loop. while not_satisfied : # Get some data. # Run our model with the data. # Adjust the model. We can already start asking important questions. For example, where do the data and model come from? How does model adjustment work? What are the interfaces of each part? What is our criteria for being satisfied? Keeping the Engine Generic We could answer the questions above by designing our engine to work with a very specific model and data. dataset = create_the_specific_dataset () model = create_the_specific_model () i = 0 while i < 1000 : data = dataset . get_next_data_for_the_specific_model () results = model . run ( data ) adjust_the_specific_model ( model , results ) But a more useful engine allows us to work with a variety of datasets and models. Such an engine would be more data- and model-agnostic, and its behavior, such as how many iterations of the training loop to perform, would be adjustable. Adding parameters to the hypothetical functions above will give us more control over the functions' behavior. But, we need a way for the user to provide values for these parameters without hard-coding the values into our engine. This is done by accepting values from outside the program, such as from the command line. As we will see later in this material, there will eventually be a lot of values to specify. To prevent our command-line interface from becoming unwieldly, we will have our users provide their custom values in a configuration file and have them pass the pathname to their configuration on the command line. To avoid taking on a new dependency, we will use JSON as our configuration language as Python has built-in support for working with it. There are many other options such as INI , TOML , and YAML . Now, the hypothetical create_the_specific_dataset() and create_the_specific_model() functions can be turned into factories that take either a loaded instance of the entire configuration or various arguments the values of which we take directly from the loaded configuration. Training Loop Criteria For our first addition to our first configuration file, we can specify the while not_satisfied (later while i < 1000 ) criteria. The training loop is typically run until one of two conditions is met. The first is that we reach a configured number of iterations. The second is that we determine that some measured metric of our model meets our expectations before we have reached the configured number of iterations. We can easily codify the first condition in our configuration file. Let's do it as { \"trainer\" : { \"num_iters\" : 1000 } } Challenge We haven't covered the interfaces between any of our components yet or what it actually looks like to load data or a model. So, build the skeleton of the engine and accomplish at least the following: Implement a command-line interface to get a pathname to a configuration file. Implement a configuration loader. The loader should have the signature load_config(config_pathname: str) -> Dict . Create the first configuration file that specifies the maximum number of trainer iterations. Stub anything left unspecified so far. As a hint, here is how we'll be structuring our source tree: configs/ engine/ trainer.py JSON configuration will live in configs/ , library code will live in engine/ , and our main program will live in trainer.py . Lastly, note that this challenge is a getting-started exercise and requires very little code to complete. We'll implement our stubs and connect things together as we progress through the material.","title":"Skeleton"},{"location":"computer_vision/learned/engine/skeleton/#engine-skeleton","text":"The \"engine\" is what we'll call the software that facilitates \"training.\"","title":"Engine Skeleton"},{"location":"computer_vision/learned/engine/skeleton/#training","text":"\"Training\" is the process of iteratively tuning a model. The core steps in training are Get some data (such as images) from a dataset. Run the data through our model. Adjust our model. Repeat until we're satisfied. These steps describe what is called the \"training loop.\" Let's codify it and start building our engine skeleton. # Training loop. while not_satisfied : # Get some data. # Run our model with the data. # Adjust the model. We can already start asking important questions. For example, where do the data and model come from? How does model adjustment work? What are the interfaces of each part? What is our criteria for being satisfied?","title":"Training"},{"location":"computer_vision/learned/engine/skeleton/#keeping-the-engine-generic","text":"We could answer the questions above by designing our engine to work with a very specific model and data. dataset = create_the_specific_dataset () model = create_the_specific_model () i = 0 while i < 1000 : data = dataset . get_next_data_for_the_specific_model () results = model . run ( data ) adjust_the_specific_model ( model , results ) But a more useful engine allows us to work with a variety of datasets and models. Such an engine would be more data- and model-agnostic, and its behavior, such as how many iterations of the training loop to perform, would be adjustable. Adding parameters to the hypothetical functions above will give us more control over the functions' behavior. But, we need a way for the user to provide values for these parameters without hard-coding the values into our engine. This is done by accepting values from outside the program, such as from the command line. As we will see later in this material, there will eventually be a lot of values to specify. To prevent our command-line interface from becoming unwieldly, we will have our users provide their custom values in a configuration file and have them pass the pathname to their configuration on the command line. To avoid taking on a new dependency, we will use JSON as our configuration language as Python has built-in support for working with it. There are many other options such as INI , TOML , and YAML . Now, the hypothetical create_the_specific_dataset() and create_the_specific_model() functions can be turned into factories that take either a loaded instance of the entire configuration or various arguments the values of which we take directly from the loaded configuration.","title":"Keeping the Engine Generic"},{"location":"computer_vision/learned/engine/skeleton/#training-loop-criteria","text":"For our first addition to our first configuration file, we can specify the while not_satisfied (later while i < 1000 ) criteria. The training loop is typically run until one of two conditions is met. The first is that we reach a configured number of iterations. The second is that we determine that some measured metric of our model meets our expectations before we have reached the configured number of iterations. We can easily codify the first condition in our configuration file. Let's do it as { \"trainer\" : { \"num_iters\" : 1000 } }","title":"Training Loop Criteria"},{"location":"computer_vision/learned/engine/skeleton/#challenge","text":"We haven't covered the interfaces between any of our components yet or what it actually looks like to load data or a model. So, build the skeleton of the engine and accomplish at least the following: Implement a command-line interface to get a pathname to a configuration file. Implement a configuration loader. The loader should have the signature load_config(config_pathname: str) -> Dict . Create the first configuration file that specifies the maximum number of trainer iterations. Stub anything left unspecified so far. As a hint, here is how we'll be structuring our source tree: configs/ engine/ trainer.py JSON configuration will live in configs/ , library code will live in engine/ , and our main program will live in trainer.py . Lastly, note that this challenge is a getting-started exercise and requires very little code to complete. We'll implement our stubs and connect things together as we progress through the material.","title":"Challenge"},{"location":"computer_vision/learned/engine/skeleton_implementation/","text":"Skeleton Implementation Here is how we implemented our skeleton. The source tree is configs \u2514\u2500\u2500 stub_config.json engine \u251c\u2500\u2500 configuration.py \u251c\u2500\u2500 datasets.py \u251c\u2500\u2500 __init__.py \u2514\u2500\u2500 models.py trainer.py trainer.py \"\"\"A model trainer.\"\"\" import argparse from engine.configuration import load_config from engine.datasets import load_dataset from engine.models import build_model def main (): parser = argparse . ArgumentParser ( description = __doc__ , formatter_class = argparse . RawDescriptionHelpFormatter ) parser . add_argument ( \"config\" , help = \"A pathname to a JSON config file\" ) args = parser . parse_args () config = load_config ( args . config ) dataset = load_dataset () model = build_model () # Training loop. for iteration in range ( config [ \"trainer\" ][ \"num_iters\" ]): pass if __name__ == \"__main__\" : main () We start by importing our configuration and dataset factories from their respective modules. We also anticipate some kind of model factory, so we import that as well. We use argparse to build the command-line interface. Our interface takes a single, required argument, a pathname to a JSON configuration file. We also make the file's docstring part of the command-line help text. Next we load our config and then the placeholders for our dataset and model . Then, we enter the training loop. Our condition, the maximum number of iterations, is taken directly from the user-provided configuration. We don't have anything to do inside the training loop yet, so we pass . configuration.py We implement our configuration loader as follows. import json from typing import Dict def load_config ( config_pathname : str ) -> Dict : \"\"\" Load a configuration from a JSON file on disk. @p config_pathname A pathname to a JSON file to load. @return The loaded configuration. \"\"\" with open ( config_pathname , \"r\" ) as f : return json . load ( f ) For our documentation, we choose the Doxygen style . We let open handle reporting issues with config_pathname such as file-not-found or not-a-regular-file errors. datasets.py Our dataset factory looks as follows. def load_dataset () -> None : \"\"\"@return None\"\"\" # Currently unimplemented. return None We have nothing to do here yet, so we simply return None . An alternative is raising NotImplementedError , but None allows us to run trainer.py from start to finish. models.py Our model factory looks very similar to our dataset one at this time. stub_config.json Our configuration looks like { \"trainer\" : { \"num_iters\" : 1 } } The value is arbitrary at this time. Running trainer.py You should be able to run trainer.py without errors in your implementation, unless you chose to raise NotImplementedError s in your stubs.","title":"Skeleton Implementation"},{"location":"computer_vision/learned/engine/skeleton_implementation/#skeleton-implementation","text":"Here is how we implemented our skeleton. The source tree is configs \u2514\u2500\u2500 stub_config.json engine \u251c\u2500\u2500 configuration.py \u251c\u2500\u2500 datasets.py \u251c\u2500\u2500 __init__.py \u2514\u2500\u2500 models.py trainer.py","title":"Skeleton Implementation"},{"location":"computer_vision/learned/engine/skeleton_implementation/#trainerpy","text":"\"\"\"A model trainer.\"\"\" import argparse from engine.configuration import load_config from engine.datasets import load_dataset from engine.models import build_model def main (): parser = argparse . ArgumentParser ( description = __doc__ , formatter_class = argparse . RawDescriptionHelpFormatter ) parser . add_argument ( \"config\" , help = \"A pathname to a JSON config file\" ) args = parser . parse_args () config = load_config ( args . config ) dataset = load_dataset () model = build_model () # Training loop. for iteration in range ( config [ \"trainer\" ][ \"num_iters\" ]): pass if __name__ == \"__main__\" : main () We start by importing our configuration and dataset factories from their respective modules. We also anticipate some kind of model factory, so we import that as well. We use argparse to build the command-line interface. Our interface takes a single, required argument, a pathname to a JSON configuration file. We also make the file's docstring part of the command-line help text. Next we load our config and then the placeholders for our dataset and model . Then, we enter the training loop. Our condition, the maximum number of iterations, is taken directly from the user-provided configuration. We don't have anything to do inside the training loop yet, so we pass .","title":"trainer.py"},{"location":"computer_vision/learned/engine/skeleton_implementation/#configurationpy","text":"We implement our configuration loader as follows. import json from typing import Dict def load_config ( config_pathname : str ) -> Dict : \"\"\" Load a configuration from a JSON file on disk. @p config_pathname A pathname to a JSON file to load. @return The loaded configuration. \"\"\" with open ( config_pathname , \"r\" ) as f : return json . load ( f ) For our documentation, we choose the Doxygen style . We let open handle reporting issues with config_pathname such as file-not-found or not-a-regular-file errors.","title":"configuration.py"},{"location":"computer_vision/learned/engine/skeleton_implementation/#datasetspy","text":"Our dataset factory looks as follows. def load_dataset () -> None : \"\"\"@return None\"\"\" # Currently unimplemented. return None We have nothing to do here yet, so we simply return None . An alternative is raising NotImplementedError , but None allows us to run trainer.py from start to finish.","title":"datasets.py"},{"location":"computer_vision/learned/engine/skeleton_implementation/#modelspy","text":"Our model factory looks very similar to our dataset one at this time.","title":"models.py"},{"location":"computer_vision/learned/engine/skeleton_implementation/#stub_configjson","text":"Our configuration looks like { \"trainer\" : { \"num_iters\" : 1 } } The value is arbitrary at this time.","title":"stub_config.json"},{"location":"computer_vision/learned/engine/skeleton_implementation/#running-trainerpy","text":"You should be able to run trainer.py without errors in your implementation, unless you chose to raise NotImplementedError s in your stubs.","title":"Running trainer.py"},{"location":"japanese/grammar/introduction/","text":"Introduction The purpose of this reference is to reinforce reading ability to expedite consuming Japanese material. This reference is not exhaustive. There is grammar in the Japanese language not present here. Also, for grammar points presented here, there are nuances not covered. Organization While certification such as that provided by the JLPT is not indicative of language mastery, the various JLPT levels do provide a convenient way to organize practical grammar points. Here we provide a catalog of grammar by approximate JLPT level. Grammar points in each level are presented in alphabetical order . Prerequisites You must know the kana. Also, while we try to use relatively simple vocabulary in the example sentences, you should understand the general-use kanji --if not the readings then at least the meanings to intuit the gist of the example sentences. How to Study this Reference Study this material with Anki . There is no need to scrape or copy content from this website. Instead, use to_csv.py to convert grammar.json into a CSV file that Anki can import. For instructions on doing this, see the tool documentation . We do not provide pre-generated CSVs at this time. References We recommend A Dictionary of Basic Japanese Grammar , A Dictionary of Intermediate Japanese Grammar , and A Dictionary of Advanced Japanese Grammar , all by Makino and Tsutsui, as supplements.","title":"Introduction"},{"location":"japanese/grammar/introduction/#introduction","text":"The purpose of this reference is to reinforce reading ability to expedite consuming Japanese material. This reference is not exhaustive. There is grammar in the Japanese language not present here. Also, for grammar points presented here, there are nuances not covered.","title":"Introduction"},{"location":"japanese/grammar/introduction/#organization","text":"While certification such as that provided by the JLPT is not indicative of language mastery, the various JLPT levels do provide a convenient way to organize practical grammar points. Here we provide a catalog of grammar by approximate JLPT level. Grammar points in each level are presented in alphabetical order .","title":"Organization"},{"location":"japanese/grammar/introduction/#prerequisites","text":"You must know the kana. Also, while we try to use relatively simple vocabulary in the example sentences, you should understand the general-use kanji --if not the readings then at least the meanings to intuit the gist of the example sentences.","title":"Prerequisites"},{"location":"japanese/grammar/introduction/#how-to-study-this-reference","text":"Study this material with Anki . There is no need to scrape or copy content from this website. Instead, use to_csv.py to convert grammar.json into a CSV file that Anki can import. For instructions on doing this, see the tool documentation . We do not provide pre-generated CSVs at this time.","title":"How to Study this Reference"},{"location":"japanese/grammar/introduction/#references","text":"We recommend A Dictionary of Basic Japanese Grammar , A Dictionary of Intermediate Japanese Grammar , and A Dictionary of Advanced Japanese Grammar , all by Makino and Tsutsui, as supplements.","title":"References"},{"location":"japanese/grammar/n4/","text":"N4 Grammar \u3044\u305f\u3059 Grammar Point Sentence 1 \u79c1\u304c \u3044\u305f\u3057\u307e\u3059 \u3002 I will do it. A humble (\u8b19\u8b72\u8a9e) form of \u3059\u308b used when talking about yourself. \u304a\u308f\u308b (\u7d42\u308f\u308b) Grammar Point Sentence 1 \u79c1\u306f\u3053\u306e\u672c\u3092\u8aad\u307f \u7d42\u308f\u308a\u307e\u3057\u305f \u3002 I finished reading this book. An auxiliary verb indicating that someone or something finishes doing something. \u304a\u301c\u306b\u306a\u308b Grammar Point Sentence 1 \u5148\u751f\u306f\u30ec\u30dd\u30fc\u30c8\u3092\u3082\u3046\u304a\u8aad\u307f \u306b\u306a\u308a\u307e\u3057\u305f \u3002 The teacher has already read the report. \u3053\u308c\u306f\u3001\u5148\u751f\u304c\u304a\u66f8\u304d \u306b\u306a\u3063\u305f \u624b\u7d19\u3067\u3059\u3002 This is a letter the teacher wrote. A phrase used to form honorific statements about someone's actions or state. \u304b Grammar Point Sentence 1 \u79c1\u306f\u672c\u3092\u8aad\u3080 \u304b \u30c6\u30ec\u30d3\u3092\u898b\u308b \u304b\u3069\u3061\u3089\u304b\u3067\u3059 \u3002 I will either read a book or watch TV. \u79c1\u306f\u672c \u304b \u6f2b\u753b\u3092\u8aad\u307f\u307e\u3059\u3002 I will read either a book or manga. A particle indicating an alternative. \u304c Grammar Point Sentence 1 \u30af\u30e9\u30b9\u306b\u306f\u672c \u304c \u3042\u308a\u307e\u3059\u3002 There is a book in the classroom. A particle which indicates the subject of a clause. \u304b\u3069\u3046\u304b Grammar Point Sentence 1 \u6f22\u5b57\u3092\u899a\u3048\u308b \u304b\u3069\u3046\u304b \u5206\u304b\u3089\u306a\u3044\u3002 I don't know whether or not I can learn kanji. \u9ad8\u304b\u3063\u305f \u304b\u3069\u3046\u304b \u77e5\u308a\u307e\u305b\u3093\u3002 I don't know whether or not it was expensive. A particle meaning \"whether or not;\" the phrase preceding it must be a yes/no question. \u3053\u3068\u304c\u3042\u308b Grammar Point Sentence 1 \u79c1\u306f\u65e5\u672c\u8a9e\u3092\u52c9\u5f37\u3057\u305f \u3053\u3068\u3042\u308b \u3002 I have studied Japanese. \u79c1\u306f\u65e5\u672c\u8a9e\u3092\u8a71\u305b\u306a\u304b\u3063\u305f \u3053\u3068\u304c\u3042\u308b \u3002 There was a time when I couldn't speak Japanese. A phrase indicating that there was a time when something happened. \u3055\u305b\u3066\u304f\u3060\u3055\u3044 Grammar Point Sentence 1 \u30ed\u30fc\u30de\u5b57\u3067\u66f8 \u304b\u305b\u3066\u304f\u3060\u3055\u3044 \u3002 Can I write in romaji? \u3053\u308c\u3092\u98df\u3079 \u3055\u305b\u3066\u304f\u3060\u3055\u3044 \u3002 Can I eat this? An auxiliary verb used to ask for permission to do something. \u3055\u305b\u3089\u308c\u308b Grammar Point Sentence 1 \u79c1\u306f\u5148\u751f\u306b\u6f22\u5b57\u3067\u66f8 \u304b\u305b\u3089\u308c\u305f \u3002 I was made to write in kanji by the teacher. \u53cb\u9054\u306f\u5f7c\u5973\u306b\u523a\u8eab\u3092\u98df\u3079 \u3055\u305b\u3089\u308c\u305f \u3002 My friend was made to eat sashimi by his girlfriend. An auxiliary verb meaning to be made to do something. \u3055\u305b\u308b Grammar Point Sentence 1 \u5148\u751f\u306f\u79c1\u306b\u6f22\u5b57\u3092\u66f8 \u304b\u305b\u305f \u3002 The teacher made me write kanji. \u79c1\u306f\u53cb\u9054\u306b\u523a\u8eab\u3092\u98df\u3079 \u3055\u305b\u305f \u3002 I made my friend eat sashimi. An auxiliary verb meaning to cause someone or something to do something. \u3059\u304e\u308b Grammar Point Sentence 1 \u3053\u306e\u672c\u306f\u96e3\u3057 \u3059\u304e\u308b \u3002 This book is too difficult. \u79c1\u306f\u52c9\u5f37\u3057 \u3059\u304e\u305f \u3002 I studied too much . An auxiliary verb indicating that something is excessive. \u305f\u3089 Grammar Point Sentence 1 \u3082\u3057\u30c6\u30b9\u30c8\u304c\u3042\u3063 \u305f\u3089 \u52c9\u5f37\u3059\u308b\u3002 If there is a test, then I'll study. \u9ad8\u304b\u3063 \u305f\u3089 \u8cb7\u308f\u306a\u3044\u3002 If it's expensive, then I won't buy it. A conjunction used to express \"if a then b\" or \"when a then b.\" \u305f\u308a Grammar Point Sentence 1 \u65e5\u672c\u8a9e\u306f\u96e3\u3057\u304b\u3063 \u305f\u308a \u6613\u3057\u304b\u3063 \u305f\u308a \u3067\u3059\u3002 Japanese is sometimes difficult and sometimes easy. \u5b66\u751f\u306f\u8aad\u3093 \u3060\u308a \u52c9\u5f37\u3057 \u305f\u308a \u3067\u3059\u3002 Students do things like reading and writing. A phrase indicating a list of things non-exhaustively. \u3060\u3059 (\u51fa\u3059) Grammar Point Sentence 1 \u5148\u751f\u306f\u6025\u306b\u8a71\u3057 \u51fa\u3057\u305f \u3002 The teacher suddenly started speaking. An auxiliary verb indicating that something has started. \u3066\u3042\u308b Grammar Point Sentence 1 \u79c1\u306f\u3082\u3046\u52c9\u5f37\u3057 \u3066\u3042\u308b \u3002 I've already studied [perhaps for some upcoming exam]. \u8aac\u660e\u306f\u3053\u306e\u672c\u306b\u306f\u66f8\u3044 \u3066\u3042\u308a\u307e\u3059 \u3002 The explanation is written in this book. An auxiliary verb indicating that something is in a resultant state, typically in anticipation or preparation for something else. \u3066\u3044\u304f Grammar Point Sentence 1 \u3053\u308c\u304b\u3089\u96e3\u3057\u304f\u306a\u3063 \u3066\u3044\u304d\u307e\u3059 \u3002 It will get more difficult from here on. An auxiliary verb indicating a continuously changing state, often translated as \"to go on ~ing.\" \u3066\u304a\u304f Grammar Point Sentence 1 \u65e5\u672c\u306b\u884c\u304f\u304b\u3089\u65e5\u672c\u8a9e\u3092\u52c9\u5f37\u3057 \u3066\u304a\u304d\u307e\u3059 \u3002 I'll study Japanese in advance because I'm going to Japan. An auxiliary verb indicating that someone does something in advance for something or someone else. \u3066\u304f\u3060\u3055\u3044\u307e\u305b\u3093\u304b Grammar Point Sentence 1 \u65e5\u672c\u8a9e\u3092\u6559\u3048\u3066 \u304f\u3060\u3055\u3044\u307e\u305b\u3093\u304b \u3002 Would you please teach me Japanese? 3 \u6642\u306b\u6765\u3066 \u304f\u3060\u3055\u3044\u307e\u305b\u3093\u304b \u3002 Would you please come at 3? An auxiliary verb used to politely make a request. \u3066\u3057\u307e\u3046 Grammar Point Sentence 1 \u3053\u306e\u672c\u3092\u8aad\u3093 \u3067\u3057\u307e\u3063\u305f \u3002 I finished reading this book. 2 \u53cb\u9054\u306e\u30d3\u30fc\u30eb\u3092\u98f2\u3093 \u3067\u3057\u307e\u3044\u307e\u3057\u305f \u3002 I accidentally drank my friend's beer. An auxiliary verb indicating completion of an action. An auxiliary verb indicating that someone did something they should not have or that something happened that should not have. \u3066\u307f\u308b Grammar Point Sentence 1 \u3053\u306e\u6f22\u5b57\u3092\u8aad\u3093 \u3067\u307f\u3066 \u304f\u3060\u3055\u3044\u3002 Please try to read this kanji. An auxiliary verb meaning to try something. \u3066\u3082\u3044\u3044 Grammar Point Sentence 1 \u3053\u306e\u672c\u3092\u8aad\u3093 \u3067\u3082\u3044\u3044 \u3067\u3059\u304b\u3002 Is it alright if I read this book? \u96e3\u3057\u304f \u3066\u3082\u3044\u3044 \u3067\u3059\u3002 It's alright if it's difficult. \u65e5\u672c\u4eba\u3058\u3083\u306a\u304f \u3066\u3082\u3044\u3044 \u3067\u3059\u3002 It's alright if you're not Japanese. A phrase expressing permission. A more polite form replaces \u3044\u3044 with \u304b\u307e\u3044 \u307e\u305b\u3093, and an even more polite form replaces \u3044\u3044 with \u3088\u308d\u3057\u3044. \u3067 Grammar Point Sentence 1 \u3053\u306e\u672c\u3092\u767e\u5186 \u3067 \u8cb7\u3044\u307e\u3057\u305f\u3002 I bought this book for 100 yen. \u5b66\u6821\u306f 3 \u6642 \u3067 \u7d42\u308f\u308a\u307e\u3059\u3002 School ends at 3 o'clock. \u79c1\u306f\u4e00\u6642\u9593 \u3067 \u30c6\u30b9\u30c8\u3092\u3057\u307e\u3057\u305f\u3002 I completed the test in one hour. A particle indicating how much time something takes, money something costs, or when something ends. \u3064\u3065\u3051\u308b \uff08\u7d9a\u3051\u308b\uff09 Grammar Point Sentence 1 \u672c\u3092\u8aad\u307f \u7d9a\u3051\u3066 \u304f\u3060\u3055\u3044\u3002 Please continue reading the book. An auxiliary verb meaning, \"to keep on doing\" or \"to continue.\" \u3068 Grammar Point Sentence 1 \u5148\u751f\u306b\u805e\u304f \u3068 \u5206\u304b\u308b\u3002 If you ask the teacher, you'll understand. \u30c6\u30b9\u30c8\u306f\u96e3\u3057\u304f\u306a\u3044 \u3068 \u8ab0\u3067\u3082\u5408\u683c\u3067\u304d\u307e\u3059\u3002 If the test is not difficult, anyone can pass it. A conjunction indicating a conditional with an uncontrollable consequence. \u3068\u3044\u3046 Grammar Point Sentence 1 \u8a66\u9a13\u306f\u96e3\u3057\u304b\u3063\u305f \u3068\u3044\u3046 \u805e\u3044\u305f\u3002 I heard that the test was hard. \u300c\u3052\u3093\u304d\u300d \u3068\u3044\u3046 \u6559\u79d1\u66f8\u3092\u4f7f\u3063\u3066\u3044\u308b\u3002 I'm using a textbook called \"Genki.\" A phrase marking information describing the thing that follows, often translated as \"that\" or \"is called.\" \u3068\u304b Grammar Point Sentence 1 \u79c1\u306f\u52c9\u5f37\u3059\u308b \u3068\u304b \u8aad\u3080\u304c\u597d\u304d\u3067\u3059\u3002 I like things such as studying and reading. \u79c1\u306f\u6620\u753b \u3068\u304b \u30a2\u30cb\u30e1 \u3068\u304b \u306f\u898b\u307e\u3059\u3002 I watch things such as movies and anime. A conjunction listing two or more things as examples, inexhaustively. \u306a\u3055\u308b Grammar Point Sentence 1 \u4f55 \u306a\u3055\u3044\u307e\u3059 \u304b\u3002 What did you do? \u5148\u751f\u306f\u3082\u3046\u304a\u6563\u6b69 \u306a\u3055\u3044\u307e\u3057\u305f \u3002 The teacher already went for a walk. The honorific (\u5c0a\u656c\u8a9e) form of \u3059\u308b. \u306a\u3051\u308c\u3070\u306a\u3089\u306a\u3044 Grammar Point Sentence 1 \u6f22\u5b57\u3092\u52c9\u5f37\u3057 \u306a\u3051\u308c\u3070\u306a\u3089\u306a\u3044 \u3002 You must study kanji. \u56f3\u66f8\u9928\u3067\u9759\u304b \u3067\u306a\u304f\u3066\u306f\u3044\u3051\u306a\u3044 \u3002 You must be quiet in the library. \u5272\u5f15\u306f\u5b66\u751f \u3067\u306a\u3044\u3068\u3044\u3051\u306a\u3044 \u3002 For the discount, you must be a student. A phrase indicating that someone must do something or that something must be in some state. There are numerous variations of this phrase. \u306a\u3089 Grammar Point Sentence 1 \u96e3\u3057\u3044 \u306a\u3089 \u52c9\u5f37\u3057\u307e\u305b\u3093\u3002 If it's difficult, I won't study it. \u65e5\u672c\u8a9e\u304c\u597d\u304d \u306a\u3089 \u52c9\u5f37\u3057\u305f\u65b9\u304c\u3044\u3044\u3002 If you like Japanese, you should study it. A conjunction meaning \"if.\" \u306b\u304f\u3044 Grammar Point Sentence 1 \u3053\u306e\u672c\u306f\u8aad\u307f \u306b\u304f\u3044 \u3067\u3059\u3002 This book is hard to read. An auxiliary adjective indicating that someone or something is difficult to ~. \u3070 Grammar Point Sentence 1 \u9ad8 \u3051\u308c\u3070 \u8cb7\u3044\u307e\u305b\u3093\u3002 If it's expensive, I won't buy it. \u30ab\u30d5\u30a7\u306f\u9759\u304b \u306a\u3089\u3070 \u52c9\u5f37\u3067\u304d\u308b\u3002 If the cafe is quiet, I can study. \u516c\u5712\u306b\u884c \u3051\u3070 \u5e3d\u5b50\u3092\u304b\u3076\u3063\u305f\u65b9\u304c\u3044\u3044\u3002 If you go to the park, you should wear a hat. A conjunction meaning \"if.\" \u306f\u3044\u3051\u306a\u3044 Grammar Point Sentence 1 \u6388\u696d\u3067\u8a71\u3057\u3066 \u306f\u3044\u3051\u307e\u305b\u3093 \u3002 You must not talk in class. A phrase indicating prohibition. \u306f\u3058\u3081\u308b (\u59cb\u3081\u308b) Grammar Point Sentence 1 \u79c1\u306f\u3053\u306e\u672c\u3092\u8aad\u307f \u59cb\u3081\u307e\u3057\u305f \u3002 I started to read this book. An auxiliary verb indicating that someone or something starts something else. \u307b\u3046\u304c\u3044\u3044 (\u65b9\u304c\u3044\u3044) Grammar Point Sentence 1 \u6f22\u5b57\u3092\u52c9\u5f37\u3057\u305f \u65b9\u304c\u3044\u3044 \u3002 You should study kanji. \u52c9\u5f37\u3092\u30b9\u30ad\u30c3\u30d7\u3057\u306a\u3044 \u65b9\u304c\u3044\u3044 \u3067\u3059\u3002 You should not skip studying. A phrase indicating that it is strongly suggested that someone do something. \u3082 Grammar Point Sentence 1 \u79c1\u306f\u3053\u306e\u672c \u3082 \u8aad\u3081\u307e\u3059\u3002 I can read even this book. \u79c1\u306f\u305d\u306e\u672c\u3092\u898b \u3082\u3057\u3066\u306a\u3044 \u3002 I haven't even seen that book. 2 \u79c1\u306f\u65e5\u672c\u8a9e \u3082 \u8a71\u3057\u307e\u3059\u3002 I speak Japanese, too . \u79c1 \u3082 \u65e5\u672c\u8a9e\u3092\u8a71\u3057\u307e\u3059\u3002 I, too , speak Japanese. A particle indicating emphasis of some object, quantity, concept, etc. A particle often translated as \"also\" or \"too.\" \u3084 Grammar Point Sentence 1 \u65e5\u672c\u8a9e\u306e\u672c \u3084 \u82f1\u8a9e\u306e\u672c\u3092\u8aad\u307f\u307e\u3059\u3002 I read Japanese and English books, among others . A conjunction listing two or more nouns as examples, inexhaustively. \u3084\u3059\u3044 Grammar Point Sentence 1 \u3053\u306e\u672c\u306f\u8aad\u307f \u3084\u3059\u3044 \u3067\u3059\u3002 This book is easy to read. An auxiliary adjective indicating that someone or something is easy to ~. \u3089\u308c\u308b Grammar Point Sentence 1 \u79c1\u306f\u5148\u751f\u306b\u53f1 \u3089\u308c\u305f \u3002 I was scolded by the teacher. \u79c1\u306f\u5148\u751f\u304b\u3089\u805e \u304b\u308c\u305f \u3002 I was asked by the teacher. 2 \u79c1\u306e\u30ec\u30dd\u30fc\u30c8\u3092\u3082\u3046\u8aad \u307e\u308c\u307e\u3057\u305f \u304b\u3002 Have you already read my report? \u3053\u308c\u306f\u3001\u5148\u751f\u304c\u66f8 \u304b\u308c\u305f \u624b\u7d19\u3067\u3059\u3002 This is a letter the teacher wrote. An auxiliary verb used to construct passive statements. An auxiliary verb used to form honorifics with a politeness less than \u307e\u3059\u306b \u306a\u308b.","title":"N4"},{"location":"japanese/grammar/n4/#n4-grammar","text":"","title":"N4 Grammar"},{"location":"japanese/grammar/n4/#_1","text":"Grammar Point Sentence 1 \u79c1\u304c \u3044\u305f\u3057\u307e\u3059 \u3002 I will do it. A humble (\u8b19\u8b72\u8a9e) form of \u3059\u308b used when talking about yourself.","title":"\u3044\u305f\u3059"},{"location":"japanese/grammar/n4/#_2","text":"Grammar Point Sentence 1 \u79c1\u306f\u3053\u306e\u672c\u3092\u8aad\u307f \u7d42\u308f\u308a\u307e\u3057\u305f \u3002 I finished reading this book. An auxiliary verb indicating that someone or something finishes doing something.","title":"\u304a\u308f\u308b (\u7d42\u308f\u308b)"},{"location":"japanese/grammar/n4/#_3","text":"Grammar Point Sentence 1 \u5148\u751f\u306f\u30ec\u30dd\u30fc\u30c8\u3092\u3082\u3046\u304a\u8aad\u307f \u306b\u306a\u308a\u307e\u3057\u305f \u3002 The teacher has already read the report. \u3053\u308c\u306f\u3001\u5148\u751f\u304c\u304a\u66f8\u304d \u306b\u306a\u3063\u305f \u624b\u7d19\u3067\u3059\u3002 This is a letter the teacher wrote. A phrase used to form honorific statements about someone's actions or state.","title":"\u304a\u301c\u306b\u306a\u308b"},{"location":"japanese/grammar/n4/#_4","text":"Grammar Point Sentence 1 \u79c1\u306f\u672c\u3092\u8aad\u3080 \u304b \u30c6\u30ec\u30d3\u3092\u898b\u308b \u304b\u3069\u3061\u3089\u304b\u3067\u3059 \u3002 I will either read a book or watch TV. \u79c1\u306f\u672c \u304b \u6f2b\u753b\u3092\u8aad\u307f\u307e\u3059\u3002 I will read either a book or manga. A particle indicating an alternative.","title":"\u304b"},{"location":"japanese/grammar/n4/#_5","text":"Grammar Point Sentence 1 \u30af\u30e9\u30b9\u306b\u306f\u672c \u304c \u3042\u308a\u307e\u3059\u3002 There is a book in the classroom. A particle which indicates the subject of a clause.","title":"\u304c"},{"location":"japanese/grammar/n4/#_6","text":"Grammar Point Sentence 1 \u6f22\u5b57\u3092\u899a\u3048\u308b \u304b\u3069\u3046\u304b \u5206\u304b\u3089\u306a\u3044\u3002 I don't know whether or not I can learn kanji. \u9ad8\u304b\u3063\u305f \u304b\u3069\u3046\u304b \u77e5\u308a\u307e\u305b\u3093\u3002 I don't know whether or not it was expensive. A particle meaning \"whether or not;\" the phrase preceding it must be a yes/no question.","title":"\u304b\u3069\u3046\u304b"},{"location":"japanese/grammar/n4/#_7","text":"Grammar Point Sentence 1 \u79c1\u306f\u65e5\u672c\u8a9e\u3092\u52c9\u5f37\u3057\u305f \u3053\u3068\u3042\u308b \u3002 I have studied Japanese. \u79c1\u306f\u65e5\u672c\u8a9e\u3092\u8a71\u305b\u306a\u304b\u3063\u305f \u3053\u3068\u304c\u3042\u308b \u3002 There was a time when I couldn't speak Japanese. A phrase indicating that there was a time when something happened.","title":"\u3053\u3068\u304c\u3042\u308b"},{"location":"japanese/grammar/n4/#_8","text":"Grammar Point Sentence 1 \u30ed\u30fc\u30de\u5b57\u3067\u66f8 \u304b\u305b\u3066\u304f\u3060\u3055\u3044 \u3002 Can I write in romaji? \u3053\u308c\u3092\u98df\u3079 \u3055\u305b\u3066\u304f\u3060\u3055\u3044 \u3002 Can I eat this? An auxiliary verb used to ask for permission to do something.","title":"\u3055\u305b\u3066\u304f\u3060\u3055\u3044"},{"location":"japanese/grammar/n4/#_9","text":"Grammar Point Sentence 1 \u79c1\u306f\u5148\u751f\u306b\u6f22\u5b57\u3067\u66f8 \u304b\u305b\u3089\u308c\u305f \u3002 I was made to write in kanji by the teacher. \u53cb\u9054\u306f\u5f7c\u5973\u306b\u523a\u8eab\u3092\u98df\u3079 \u3055\u305b\u3089\u308c\u305f \u3002 My friend was made to eat sashimi by his girlfriend. An auxiliary verb meaning to be made to do something.","title":"\u3055\u305b\u3089\u308c\u308b"},{"location":"japanese/grammar/n4/#_10","text":"Grammar Point Sentence 1 \u5148\u751f\u306f\u79c1\u306b\u6f22\u5b57\u3092\u66f8 \u304b\u305b\u305f \u3002 The teacher made me write kanji. \u79c1\u306f\u53cb\u9054\u306b\u523a\u8eab\u3092\u98df\u3079 \u3055\u305b\u305f \u3002 I made my friend eat sashimi. An auxiliary verb meaning to cause someone or something to do something.","title":"\u3055\u305b\u308b"},{"location":"japanese/grammar/n4/#_11","text":"Grammar Point Sentence 1 \u3053\u306e\u672c\u306f\u96e3\u3057 \u3059\u304e\u308b \u3002 This book is too difficult. \u79c1\u306f\u52c9\u5f37\u3057 \u3059\u304e\u305f \u3002 I studied too much . An auxiliary verb indicating that something is excessive.","title":"\u3059\u304e\u308b"},{"location":"japanese/grammar/n4/#_12","text":"Grammar Point Sentence 1 \u3082\u3057\u30c6\u30b9\u30c8\u304c\u3042\u3063 \u305f\u3089 \u52c9\u5f37\u3059\u308b\u3002 If there is a test, then I'll study. \u9ad8\u304b\u3063 \u305f\u3089 \u8cb7\u308f\u306a\u3044\u3002 If it's expensive, then I won't buy it. A conjunction used to express \"if a then b\" or \"when a then b.\"","title":"\u305f\u3089"},{"location":"japanese/grammar/n4/#_13","text":"Grammar Point Sentence 1 \u65e5\u672c\u8a9e\u306f\u96e3\u3057\u304b\u3063 \u305f\u308a \u6613\u3057\u304b\u3063 \u305f\u308a \u3067\u3059\u3002 Japanese is sometimes difficult and sometimes easy. \u5b66\u751f\u306f\u8aad\u3093 \u3060\u308a \u52c9\u5f37\u3057 \u305f\u308a \u3067\u3059\u3002 Students do things like reading and writing. A phrase indicating a list of things non-exhaustively.","title":"\u305f\u308a"},{"location":"japanese/grammar/n4/#_14","text":"Grammar Point Sentence 1 \u5148\u751f\u306f\u6025\u306b\u8a71\u3057 \u51fa\u3057\u305f \u3002 The teacher suddenly started speaking. An auxiliary verb indicating that something has started.","title":"\u3060\u3059 (\u51fa\u3059)"},{"location":"japanese/grammar/n4/#_15","text":"Grammar Point Sentence 1 \u79c1\u306f\u3082\u3046\u52c9\u5f37\u3057 \u3066\u3042\u308b \u3002 I've already studied [perhaps for some upcoming exam]. \u8aac\u660e\u306f\u3053\u306e\u672c\u306b\u306f\u66f8\u3044 \u3066\u3042\u308a\u307e\u3059 \u3002 The explanation is written in this book. An auxiliary verb indicating that something is in a resultant state, typically in anticipation or preparation for something else.","title":"\u3066\u3042\u308b"},{"location":"japanese/grammar/n4/#_16","text":"Grammar Point Sentence 1 \u3053\u308c\u304b\u3089\u96e3\u3057\u304f\u306a\u3063 \u3066\u3044\u304d\u307e\u3059 \u3002 It will get more difficult from here on. An auxiliary verb indicating a continuously changing state, often translated as \"to go on ~ing.\"","title":"\u3066\u3044\u304f"},{"location":"japanese/grammar/n4/#_17","text":"Grammar Point Sentence 1 \u65e5\u672c\u306b\u884c\u304f\u304b\u3089\u65e5\u672c\u8a9e\u3092\u52c9\u5f37\u3057 \u3066\u304a\u304d\u307e\u3059 \u3002 I'll study Japanese in advance because I'm going to Japan. An auxiliary verb indicating that someone does something in advance for something or someone else.","title":"\u3066\u304a\u304f"},{"location":"japanese/grammar/n4/#_18","text":"Grammar Point Sentence 1 \u65e5\u672c\u8a9e\u3092\u6559\u3048\u3066 \u304f\u3060\u3055\u3044\u307e\u305b\u3093\u304b \u3002 Would you please teach me Japanese? 3 \u6642\u306b\u6765\u3066 \u304f\u3060\u3055\u3044\u307e\u305b\u3093\u304b \u3002 Would you please come at 3? An auxiliary verb used to politely make a request.","title":"\u3066\u304f\u3060\u3055\u3044\u307e\u305b\u3093\u304b"},{"location":"japanese/grammar/n4/#_19","text":"Grammar Point Sentence 1 \u3053\u306e\u672c\u3092\u8aad\u3093 \u3067\u3057\u307e\u3063\u305f \u3002 I finished reading this book. 2 \u53cb\u9054\u306e\u30d3\u30fc\u30eb\u3092\u98f2\u3093 \u3067\u3057\u307e\u3044\u307e\u3057\u305f \u3002 I accidentally drank my friend's beer. An auxiliary verb indicating completion of an action. An auxiliary verb indicating that someone did something they should not have or that something happened that should not have.","title":"\u3066\u3057\u307e\u3046"},{"location":"japanese/grammar/n4/#_20","text":"Grammar Point Sentence 1 \u3053\u306e\u6f22\u5b57\u3092\u8aad\u3093 \u3067\u307f\u3066 \u304f\u3060\u3055\u3044\u3002 Please try to read this kanji. An auxiliary verb meaning to try something.","title":"\u3066\u307f\u308b"},{"location":"japanese/grammar/n4/#_21","text":"Grammar Point Sentence 1 \u3053\u306e\u672c\u3092\u8aad\u3093 \u3067\u3082\u3044\u3044 \u3067\u3059\u304b\u3002 Is it alright if I read this book? \u96e3\u3057\u304f \u3066\u3082\u3044\u3044 \u3067\u3059\u3002 It's alright if it's difficult. \u65e5\u672c\u4eba\u3058\u3083\u306a\u304f \u3066\u3082\u3044\u3044 \u3067\u3059\u3002 It's alright if you're not Japanese. A phrase expressing permission. A more polite form replaces \u3044\u3044 with \u304b\u307e\u3044 \u307e\u305b\u3093, and an even more polite form replaces \u3044\u3044 with \u3088\u308d\u3057\u3044.","title":"\u3066\u3082\u3044\u3044"},{"location":"japanese/grammar/n4/#_22","text":"Grammar Point Sentence 1 \u3053\u306e\u672c\u3092\u767e\u5186 \u3067 \u8cb7\u3044\u307e\u3057\u305f\u3002 I bought this book for 100 yen. \u5b66\u6821\u306f 3 \u6642 \u3067 \u7d42\u308f\u308a\u307e\u3059\u3002 School ends at 3 o'clock. \u79c1\u306f\u4e00\u6642\u9593 \u3067 \u30c6\u30b9\u30c8\u3092\u3057\u307e\u3057\u305f\u3002 I completed the test in one hour. A particle indicating how much time something takes, money something costs, or when something ends.","title":"\u3067"},{"location":"japanese/grammar/n4/#_23","text":"Grammar Point Sentence 1 \u672c\u3092\u8aad\u307f \u7d9a\u3051\u3066 \u304f\u3060\u3055\u3044\u3002 Please continue reading the book. An auxiliary verb meaning, \"to keep on doing\" or \"to continue.\"","title":"\u3064\u3065\u3051\u308b \uff08\u7d9a\u3051\u308b\uff09"},{"location":"japanese/grammar/n4/#_24","text":"Grammar Point Sentence 1 \u5148\u751f\u306b\u805e\u304f \u3068 \u5206\u304b\u308b\u3002 If you ask the teacher, you'll understand. \u30c6\u30b9\u30c8\u306f\u96e3\u3057\u304f\u306a\u3044 \u3068 \u8ab0\u3067\u3082\u5408\u683c\u3067\u304d\u307e\u3059\u3002 If the test is not difficult, anyone can pass it. A conjunction indicating a conditional with an uncontrollable consequence.","title":"\u3068"},{"location":"japanese/grammar/n4/#_25","text":"Grammar Point Sentence 1 \u8a66\u9a13\u306f\u96e3\u3057\u304b\u3063\u305f \u3068\u3044\u3046 \u805e\u3044\u305f\u3002 I heard that the test was hard. \u300c\u3052\u3093\u304d\u300d \u3068\u3044\u3046 \u6559\u79d1\u66f8\u3092\u4f7f\u3063\u3066\u3044\u308b\u3002 I'm using a textbook called \"Genki.\" A phrase marking information describing the thing that follows, often translated as \"that\" or \"is called.\"","title":"\u3068\u3044\u3046"},{"location":"japanese/grammar/n4/#_26","text":"Grammar Point Sentence 1 \u79c1\u306f\u52c9\u5f37\u3059\u308b \u3068\u304b \u8aad\u3080\u304c\u597d\u304d\u3067\u3059\u3002 I like things such as studying and reading. \u79c1\u306f\u6620\u753b \u3068\u304b \u30a2\u30cb\u30e1 \u3068\u304b \u306f\u898b\u307e\u3059\u3002 I watch things such as movies and anime. A conjunction listing two or more things as examples, inexhaustively.","title":"\u3068\u304b"},{"location":"japanese/grammar/n4/#_27","text":"Grammar Point Sentence 1 \u4f55 \u306a\u3055\u3044\u307e\u3059 \u304b\u3002 What did you do? \u5148\u751f\u306f\u3082\u3046\u304a\u6563\u6b69 \u306a\u3055\u3044\u307e\u3057\u305f \u3002 The teacher already went for a walk. The honorific (\u5c0a\u656c\u8a9e) form of \u3059\u308b.","title":"\u306a\u3055\u308b"},{"location":"japanese/grammar/n4/#_28","text":"Grammar Point Sentence 1 \u6f22\u5b57\u3092\u52c9\u5f37\u3057 \u306a\u3051\u308c\u3070\u306a\u3089\u306a\u3044 \u3002 You must study kanji. \u56f3\u66f8\u9928\u3067\u9759\u304b \u3067\u306a\u304f\u3066\u306f\u3044\u3051\u306a\u3044 \u3002 You must be quiet in the library. \u5272\u5f15\u306f\u5b66\u751f \u3067\u306a\u3044\u3068\u3044\u3051\u306a\u3044 \u3002 For the discount, you must be a student. A phrase indicating that someone must do something or that something must be in some state. There are numerous variations of this phrase.","title":"\u306a\u3051\u308c\u3070\u306a\u3089\u306a\u3044"},{"location":"japanese/grammar/n4/#_29","text":"Grammar Point Sentence 1 \u96e3\u3057\u3044 \u306a\u3089 \u52c9\u5f37\u3057\u307e\u305b\u3093\u3002 If it's difficult, I won't study it. \u65e5\u672c\u8a9e\u304c\u597d\u304d \u306a\u3089 \u52c9\u5f37\u3057\u305f\u65b9\u304c\u3044\u3044\u3002 If you like Japanese, you should study it. A conjunction meaning \"if.\"","title":"\u306a\u3089"},{"location":"japanese/grammar/n4/#_30","text":"Grammar Point Sentence 1 \u3053\u306e\u672c\u306f\u8aad\u307f \u306b\u304f\u3044 \u3067\u3059\u3002 This book is hard to read. An auxiliary adjective indicating that someone or something is difficult to ~.","title":"\u306b\u304f\u3044"},{"location":"japanese/grammar/n4/#_31","text":"Grammar Point Sentence 1 \u9ad8 \u3051\u308c\u3070 \u8cb7\u3044\u307e\u305b\u3093\u3002 If it's expensive, I won't buy it. \u30ab\u30d5\u30a7\u306f\u9759\u304b \u306a\u3089\u3070 \u52c9\u5f37\u3067\u304d\u308b\u3002 If the cafe is quiet, I can study. \u516c\u5712\u306b\u884c \u3051\u3070 \u5e3d\u5b50\u3092\u304b\u3076\u3063\u305f\u65b9\u304c\u3044\u3044\u3002 If you go to the park, you should wear a hat. A conjunction meaning \"if.\"","title":"\u3070"},{"location":"japanese/grammar/n4/#_32","text":"Grammar Point Sentence 1 \u6388\u696d\u3067\u8a71\u3057\u3066 \u306f\u3044\u3051\u307e\u305b\u3093 \u3002 You must not talk in class. A phrase indicating prohibition.","title":"\u306f\u3044\u3051\u306a\u3044"},{"location":"japanese/grammar/n4/#_33","text":"Grammar Point Sentence 1 \u79c1\u306f\u3053\u306e\u672c\u3092\u8aad\u307f \u59cb\u3081\u307e\u3057\u305f \u3002 I started to read this book. An auxiliary verb indicating that someone or something starts something else.","title":"\u306f\u3058\u3081\u308b (\u59cb\u3081\u308b)"},{"location":"japanese/grammar/n4/#_34","text":"Grammar Point Sentence 1 \u6f22\u5b57\u3092\u52c9\u5f37\u3057\u305f \u65b9\u304c\u3044\u3044 \u3002 You should study kanji. \u52c9\u5f37\u3092\u30b9\u30ad\u30c3\u30d7\u3057\u306a\u3044 \u65b9\u304c\u3044\u3044 \u3067\u3059\u3002 You should not skip studying. A phrase indicating that it is strongly suggested that someone do something.","title":"\u307b\u3046\u304c\u3044\u3044 (\u65b9\u304c\u3044\u3044)"},{"location":"japanese/grammar/n4/#_35","text":"Grammar Point Sentence 1 \u79c1\u306f\u3053\u306e\u672c \u3082 \u8aad\u3081\u307e\u3059\u3002 I can read even this book. \u79c1\u306f\u305d\u306e\u672c\u3092\u898b \u3082\u3057\u3066\u306a\u3044 \u3002 I haven't even seen that book. 2 \u79c1\u306f\u65e5\u672c\u8a9e \u3082 \u8a71\u3057\u307e\u3059\u3002 I speak Japanese, too . \u79c1 \u3082 \u65e5\u672c\u8a9e\u3092\u8a71\u3057\u307e\u3059\u3002 I, too , speak Japanese. A particle indicating emphasis of some object, quantity, concept, etc. A particle often translated as \"also\" or \"too.\"","title":"\u3082"},{"location":"japanese/grammar/n4/#_36","text":"Grammar Point Sentence 1 \u65e5\u672c\u8a9e\u306e\u672c \u3084 \u82f1\u8a9e\u306e\u672c\u3092\u8aad\u307f\u307e\u3059\u3002 I read Japanese and English books, among others . A conjunction listing two or more nouns as examples, inexhaustively.","title":"\u3084"},{"location":"japanese/grammar/n4/#_37","text":"Grammar Point Sentence 1 \u3053\u306e\u672c\u306f\u8aad\u307f \u3084\u3059\u3044 \u3067\u3059\u3002 This book is easy to read. An auxiliary adjective indicating that someone or something is easy to ~.","title":"\u3084\u3059\u3044"},{"location":"japanese/grammar/n4/#_38","text":"Grammar Point Sentence 1 \u79c1\u306f\u5148\u751f\u306b\u53f1 \u3089\u308c\u305f \u3002 I was scolded by the teacher. \u79c1\u306f\u5148\u751f\u304b\u3089\u805e \u304b\u308c\u305f \u3002 I was asked by the teacher. 2 \u79c1\u306e\u30ec\u30dd\u30fc\u30c8\u3092\u3082\u3046\u8aad \u307e\u308c\u307e\u3057\u305f \u304b\u3002 Have you already read my report? \u3053\u308c\u306f\u3001\u5148\u751f\u304c\u66f8 \u304b\u308c\u305f \u624b\u7d19\u3067\u3059\u3002 This is a letter the teacher wrote. An auxiliary verb used to construct passive statements. An auxiliary verb used to form honorifics with a politeness less than \u307e\u3059\u306b \u306a\u308b.","title":"\u3089\u308c\u308b"},{"location":"japanese/grammar/n5/","text":"N5 Grammar \u3042\u3052\u308b Grammar Point Sentence 1 \u65e5\u672c\u8a9e\u3092\u6559\u3048\u3066 \u3042\u3052\u307e\u3059 \u3002 I will teach you Japanese. \u3053\u306e\u672c\u3092 \u3042\u3052\u307e\u3059 \u3002 I'll give you this book. An auxiliary verb indicating that the speaker gives something or some action to someone else. When speaking to someone of lower status, \u3042\u3052\u308b can be replaced with \u3084\u308b. The honorific form is \u3055\u3057\u3042\u3052\u308b. \u3042\u3068\u3067 (\u5f8c\u3067) Grammar Point Sentence 1 \u65e5\u672c\u8a9e\u3092\u52c9\u5f37\u3057\u305f \u5f8c\u3067 \u5bdd\u307e\u3057\u305f\u3002 I slept after studying Japanese. \u30af\u30e9\u30b9\u306e \u5f8c\u3067 \u5e30\u308a\u307e\u3057\u305f\u3002 I went home after class. A conjunction indicating that something takes place after something else. \u304b Grammar Point Sentence 1 \u79c1\u306f\u82f1\u8a9e \u304b \u65e5\u672c\u8a9e\u3092\u52c9\u5f37\u3057\u307e\u3059\u3002 I will study either English or Japanese. \u660e\u65e5\u6388\u696d\u304c\u3042\u308b \u304b \u306a\u3044 \u304b \u5206\u304b\u308a\u307e\u305b\u3093\u3002 I don't know whether there is class tomorrow or not. A grammar particle which indicates an alternative. \u304b\u305f (\u65b9) Grammar Point Sentence 1 \u305d\u306e\u6f22\u5b57\u306e\u66f8\u304d \u65b9 \u304c\u5206\u304b\u308a\u307e\u305b\u3093\u3002 I don't know how to write that kanji. A nominalizing suffix indicating a way of doing something. \u304b\u3089 Grammar Point Sentence 1 \u6765\u5e74\u65e5\u672c\u3078\u884c\u304f \u304b\u3089 \u65e5\u672c\u8a9e\u3092\u52c9\u5f37\u3059\u308b\u3002 I'm studying Japanese because I'm going to Japan next year. \u9ad8\u304b\u3063\u305f \u304b\u3089 \u8cb7\u3044\u307e\u305b\u3093\u3067\u3057\u305f\u3002 I didn't buy it because it was expensive. 2 \u65e5\u672c\u8a9e\u3092\u52c9\u5f37\u3057\u3066 \u304b\u3089 \u5168\u90e8\u3092\u5fd8\u308c\u307e\u3057\u305f\u3002 After studying Japanese, I forgot everything. A conjunction indicating a reason or cause. A conjunction indicating after or since something takes place. \u304f\u3089\u3044 Grammar Point Sentence 1 \u767e\u4e94\u5341\u5186 \u304f\u3089\u3044 \u3067\u3057\u305f\u3002 It was about 150 yen. \u4e8c\u6642\u9593 \u304f\u3089\u3044 \u304b\u304b\u308a\u307e\u3059\u3002 It takes about 2 hours. A particle indicating an approximate quantity or otherwise translated as \"about.\" \u3050\u3089\u3044 has the same meaning. \u304f\u308c\u308b Grammar Point Sentence 1 \u5f7c\u306f\u65e5\u672c\u8a9e\u3092\u6559\u3048\u3066 \u304f\u308c\u307e\u3057\u305f \u3002 He taught me Japanese. \u5f7c\u306f\u3053\u306e\u672c\u3092 \u304f\u308c\u307e\u3057\u305f \u3002 He gave me this book. An auxiliary verb indicating that someone gives something or does some action for someone else. The honorific form is \u304f\u3060\u3055\u308b. \u3053\u3068 Grammar Point Sentence 1 \u65e5\u672c\u8a9e\u3067\u66f8\u304f \u3053\u3068 \u306f\u96e3\u3057\u3002 It's difficult to write in Japanese. A nominalizer; it suggests the speaker is not as emotionally close to the concept compared to if the speaker had used \u306e. \u3053\u3093\u306a Grammar Point Sentence 1 \u3053\u3093\u306a \u672c\u3092\u8cb7\u3044\u305f\u3044\u3067\u3059\u3002 I'd like to buy a book like this . \u305d\u3093\u306a \u3053\u3068\u3057\u306a\u3044\u3067\u3088\uff01 Don't do such a thing ! A word meaning \"such a thing\" or \"this sort of thing.\" It can be adjusted for proximity to the speaker (\u305d\u3093\u306a\u3001\u3042\u3093\u306a) or be made inquisitive (\u3069\u3093\u306a). \u3053\u3093\u306a\u306b Grammar Point Sentence 1 \u305d\u3093\u306a\u306b \u96e3\u3057\u304b\u3063\u305f\uff1f Was it that difficult? \u3053\u3093\u306a\u306b \u7f8e\u5473\u3057\u3044\u3053\u3068\u8ab0\u3067\u3082\u597d\u304d\u3067\u3059\u3002 Anyone likes something delicious like this . A word meaning \"like this.\" It can be adjusted for proximity to the speaker ( \u305d\u3093\u306a\u306b\u3001\u3042\u3093\u306a\u306b). \u3055 Grammar Point Sentence 1 \u65e5\u672c\u8a9e\u306e\u96e3\u3057 \u3055 \u304c\u3088\u304f\u5206\u304b\u3063\u3066\u308b\u3002 I know the difficulty of Japanese. A nominalizing suffix attachable to the stem of adjectives. \u3057\u304b Grammar Point Sentence 1 \u65e5\u672c\u8a9e \u3057\u304b \u52c9\u5f37\u3057\u307e\u305b\u3093\u3002 I study only Japanese. A particle indicating that something S and only S is the case, often translated as \"nothing,\" \"nobody,\" or \"only.\" \u3059\u3050 Grammar Point Sentence 1 \u671d\u8d77\u304d\u3066 \u3059\u3050 \u306b\u65e5\u672c\u8a9e\u3092\u52c9\u5f37\u3057\u307e\u3059\u3002 As soon as I wake up, I study Japanese. \u5b66\u6821\u306f\u99c5\u306e \u3059\u3050 \u524d\u3067\u3059\u3002 The school is right in front of the station. An adverb indicating not much temporal or physical distance, often translated as \"as soon as,\" \"immediately,\" \"right.\" \u305f\u3044 Grammar Point Sentence 1 \u79c1\u306f\u65e5\u672c\u8a9e\u3092\u52c9\u5f37\u3057 \u305f\u3044 \u3067\u3059\u3002 I want to study Japanese. \u79c1\u306f\u523a\u8eab\u3092\u98df\u3079 \u305f\u3044 \u3067\u3059\u3002 I want to eat sashimi. An auxiliary adjective indicating the desire to do something. \u3060\u3051 Grammar Point Sentence 1 \u65e5\u672c\u8a9e\u304c\u52c9\u5f37\u3057\u305f \u3060\u3051 \u3067\u3059\u3002 I just studied (and did nothing else with) Japanese. \u79c1 \u3060\u3051 \u65e5\u672c\u8a9e\u3092\u8a71\u305b\u307e\u3059\u3002 Only I can speak Japanese. A particle expressing a limit on something, often translated as \"just,\" \"merely,\" \"only,\" or \"that's all.\" \u3060\u308d\u3046 See \u3067\u3057\u3087\u3046. \u305f\u3081 Grammar Point Sentence 1 \u8a66\u9a13\u306e \u305f\u3081 \u306b\u52c9\u5f37\u3057\u307e\u3059\u3002 I'm studying in preparation for exams. \u65e5\u672c\u8a9e\u3092\u52c9\u5f37\u3059\u308b \u305f\u3081 \u306b\u65e5\u672c\u306b\u884c\u304d\u307e\u3059\u3002 I'm going to Japan in order to study Japanese. \u75c5\u6c17\u306b\u306a\u3063\u305f \u305f\u3081 \u3001\u30af\u30e9\u30b9\u306b\u884c\u304b\u306a\u304b\u3063\u305f\u3002 Because I got sick, I didn't go to class. A noun expressing a purpose, reason, or cause. \u3063\u3066 Grammar Point Sentence 1 \u5f7c\u5973\u306f\u65e5\u672c\u8a9e\u3092\u52c9\u5f37\u3059\u308b \u3063\u3066 \u8a00\u3063\u305f\u3002 She said she studies Japanese. \u79c1\u306f\u65e5\u672c\u8a9e\u3092\u52c9\u5f37\u3057\u3088\u3046\u304b \u3063\u3066 \u601d\u3044\u307e\u3059\u3002 I wonder if I should study Japanese. A colloquial particle indicating a quotation. \u3066 Grammar Point Sentence 1 \u79c1\u306f\u65e5\u672c\u3078\u884c\u3063 \u3066 \u52c9\u5f37\u3057\u307e\u3057\u305f\u3002 I went to Japan and studied. \u3053\u308c\u306f\u9ad8\u304f \u3066 \u7f8e\u5473\u3057\u3044\u3002 This is expensive and delicious. \u5f7c\u306f\u5148\u751f \u3067 \u512a\u3057\u3044\u3002 He is a teacher, and he is nice. A verb or i-adjective ending indicating \"and.\" For na-adjectives and nouns, \u3066 becomes \u3067 instead. \u3067 Grammar Point Sentence 1 \u65e5\u672c\u4eba\u306f\u306f\u3057 \u3067 \u98df\u3079\u307e\u3059\u3002 Japanese people eat with chopsticks. \u3053\u308c\u306f\u65e5\u672c\u8a9e \u3067 \u4f55\u3067\u3059\u304b\u3002 What is this in Japanese? A grammar particle which indicates the use of something for doing something. \u3067\u3057\u3087\u3046 Grammar Point Sentence 1 \u5f7c\u306f\u65e5\u672c\u8a9e\u3067\u8a71\u3059 \u3067\u3057\u3087\u3046 \u3002 He will probably speak in Japanese. \u3053\u306e\u672c\u306f\u9ad8\u3044 \u3060\u308d\u3046 \u3002 This book is probably expensive. An auxiliary indicating conjecture grounded in no substantial evidence. \u3060\u308d \u3046 is the informal form. \u3067\u3082 Grammar Point Sentence 1 \u65e5\u672c\u8a9e \u3067\u3082 \u8a71\u305b\u307e\u3059\u3002 I can speak even Japanese. \u5b50\u4f9b \u3067\u3082 \u305d\u306e\u3053\u3068\u3092\u3067\u304d\u307e\u3059\u3002 Even a child can do that. A particle meaning \"even.\" \u3068 Grammar Point Sentence 1 \u79c1\u306f\u3042\u306a\u305f \u3068 \u65e5\u672c\u8a9e\u3092\u52c9\u5f37\u3057\u307e\u3059\u3002 I study Japanese with you. \u79c1\u306f\u65e5\u672c\u4eba \u3068 \u7d50\u5a5a\u3057\u307e\u3057\u305f\u3002 I (got) married ( to ) a Japanese person. A grammar particle indicating a reciprocal relationship with the subject. \u3069\u3046 Grammar Point Sentence 1 \u65e5\u672c\u8a9e\u3067 \u3069\u3046 \u8a00\u3044\u307e\u3059\u304b\u3002 How do you say it in Japanese? \u672c\u306f \u3069\u3046 \u3067\u3057\u305f\u304b\u3002 How was the book? A grammar particle which asks about the state of something or someone or the way of doing something. \u3068\u540c\u3058\u304f\u3089\u3044\u301c Grammar Point Sentence 1 \u3053\u306e\u672c\u306f\u305d\u306e\u672c \u3068\u540c\u3058\u304f\u3089\u3044 \u9762\u767d\u3044\u3002 This book is as interesting as that one. A phrase indicating that one thing is as \u301c as another. \u3068\u304d Grammar Point Sentence 1 \u65e5\u672c\u8a9e\u3092\u52c9\u5f37\u3059\u308b \u6642 \u672c\u3092\u305f\u304f\u3055\u3093\u8aad\u307f\u307e\u3059\u3002 When I study Japanese I read a lot of books. \u9759\u304b\u306a \u6642 \u52c9\u5f37\u3067\u304d\u307e\u3059\u3002 I'm able to study when it's quiet. A dependent noun indicating a time when someone or something did or does something. \u3069\u3061\u3089 Grammar Point Sentence 1 \u65e5\u672c\u8a9e\u3068\u82f1\u8a9e\u3068\u3001 \u3069\u3061\u3089 \u304c\u9762\u767d\u3044\uff1f Between Japanese and English, which is more interesting? A word meaning \"which,\" among a group of things, particularly two. \u3069\u308c Grammar Point Sentence 1 \u9ec4\u8272\u3068\u7d2b\u8272\u3068\u9752\u8272\u3067\u3001 \u3069\u308c \u304c\u4e00\u756a\u7f8e\u3057\u3044\u3067\u3059\u304b\u3002 Between yellow, purple, and blue, which is the most beautiful? A word meaning \"which,\" among a group of 3 or more. \u306a\u3044\u3067 Grammar Point Sentence 1 \u52c9\u5f37\u3057 \u306a\u3044\u3067 \u5b66\u6821\u3078\u6765\u307e\u3057\u305f\u3002 I came to school without studying. A negative te-form indicating not doing something or without doing something. \u306a\u3055\u3044 Grammar Point Sentence 1 \u65e5\u672c\u8a9e\u3092\u52c9\u5f37\u3057 \u306a\u3055\u3044 \u3002 Study Japanese. An auxiliary verb which creates an imperative. \u306a\u304c\u3089 Grammar Point Sentence 1 \u672c\u3092\u8aad\u307f \u306a\u304c\u3089 \u5b66\u6821\u3078\u6b69\u304d\u307e\u3057\u305f\u3002 I walked to school while reading a book. A conjunction indicating the surrounding clauses happen simultaneously, often translated as \"while\" or \"with.\" \u306a\u308b Grammar Point Sentence 1 \u3042\u306a\u305f\u306e\u65e5\u672c\u8a9e\u304c\u4e0a\u624b\u306b \u306a\u308a\u307e\u3057\u305f \u3002 You've become good at Japanese. \u5bd2\u304f \u306a\u308a\u307e\u3057\u305f \u3002 It's become cold. A word meaning \"to become\" or \"come to be.\" \u306b Grammar Point Sentence 1 \u65e5\u672c\u8a9e\u3092\u52c9\u5f37\uff08\u3057\uff09 \u306b \u5b66\u6821\u3078\u884c\u304d\u307e\u3059\u3002 I'm going to school (in order) to study Japanese. \u672c\u3092\u8cb7\u3044 \u306b \u6765\u307e\u3057\u305f\u3002 I came (in order) to buy a book. A particle indicating the purpose of movement. This construct is only used with motion verbs like \u884c\u304f, \u6765\u308b, \u5e30\u308b, \u5165\u308b, and \u51fa\u308b. \u306e Grammar Point Sentence 1 \u672c\u306f\u65e5\u672c\u8a9e \u306e \u3092\u8cb7\u3044\u307e\u3057\u305f\u3002 As for books, I bought a Japanese one . \u3042\u306e\u672c\u306f\u30c8\u30e0 \u306e \u3067\u3059\u3002 That book is Tom's book . 2 \u3069\u3046\u3057\u3066\u52c9\u5f37\u3057\u3066\u3044\u308b \u306e \uff1f Why are you studying ( you've got to tell me )? \u660e\u65e5\u30c6\u30b9\u30c8\u304c\u3042\u308b \u306e \u3002 Because there's a test tomorrow. 3 \u52c9\u5f37\u3059\u308b \u306e \u306f\u96e3\u3057\u3044\u3002 Studying is difficult. \u5f7c\u304c\u65e5\u672c\u8a9e\u3092\u8a71\u3059 \u306e \u3092\u805e\u304d\u307e\u3057\u305f\u3002 I heard him speaking Japanese. A dependent, indefinite pronoun indicating \"one\" or \"_'s.\" An informal sentence-final particle indicating an explanation or asking for an explanation, used by children or female speakers. If male speakers use it, it is only for questions. A clause nominalizer. \u306e\u3067\u3059 Grammar Point Sentence 1 \u4f55\u3092\u3057\u3066\u3044\u308b \u3093\u3067\u3059 \u304b\u3002 What are you doing ( you've got to tell me )? \u65e5\u672c\u8a9e\u3092\u52c9\u5f37\u3057\u3066\u3044\u308b \u306e\u3067\u3059 \u3002 ( The explanation is that ) I'm studying Japanese. A sentence-ending phrase indicating an explanation or asking for an explanation. An informal form is \u3093\u3067\u3059. \u3070\u304b\u308a Grammar Point Sentence 1 \u65e5\u672c\u8a9e \u3070\u304b\u308a \u52c9\u5f37\u3057\u3066\u3044\u307e\u3059\u3002 I'm studying only Japanese. \u79c1\u306f\u52c9\u5f37\u3057\u305f \u3070\u304b\u308a \u3067\u3059\u3002 I studied and haven't done anything else . A particle indicating that something is the only state, thing, or action. \u307b\u3046 Grammar Point Sentence 1 \u3042\u306a\u305f\u306e\u672c\u306f\u3069\u3063\u3061\u3067\u3059\u304b\u3002 Which book is yours? \u5927\u304d\u3044 \u307b\u3046 \u3067\u3059\u3002 The bigger one. \u597d\u304d\u306a \u307b\u3046 \u3092\u53d6\u3063\u3066\u304f\u3060\u3055\u3044\u3002 Please take the one you like most . A word indicating more than or greater in a comparison. It comes from the form \u307b\u3046\u304c\u301c\u3088\u308a. \u307b\u3046\u304c\u301c\u3088\u308a Grammar Point Sentence 1 \u65e5\u672c\u8a9e\u306e \u307b\u3046\u304c \u82f1\u8a9e \u3088\u308a \u9762\u767d\u3044\u3002 Japanese is more interesting than English. \u904a\u3076 \u307b\u3046\u304c \u52c9\u5f37\u3059\u308b \u3088\u308a \u697d\u3057\u3044\u3002 Playing is more fun than studying. A phrase for comparing two things, where one is more or greater than the other. \u307b\u3069 Grammar Point Sentence 1 \u82f1\u8a9e\u306f\u65e5\u672c\u8a9e \u307b\u3069 \u9762\u767d\u304f\u306a\u3044\u3002 English is not as interesting as Japanese. A particle indicating an extent or degree, often translated as \"[not] as ~ as ~.\" \u307e\u3048\u306b (\u524d\u306b) Grammar Point Sentence 1 \u5bdd\u308b \u524d\u306b \u65e5\u672c\u8a9e\u3092\u52c9\u5f37\u3057\u307e\u3059\u3002 I study Japanese before I sleep. \u30c6\u30b9\u30c8\u306e \u524d\u306b \u52c9\u5f37\u3057\u307e\u3059\u3002 I'll study before the test. A conjunction indicating in front of or before something occurs. \u307e\u3060 Grammar Point Sentence 1 \u307e\u3060 \u65e5\u672c\u8a9e\u3092\u5206\u304b\u308a\u307e\u305b\u3093\u3002 I still don't understand Japanese. \u79c1\u306f \u307e\u3060 \u52c9\u5f37\u3057\u3066\u3044\u307e\u3059\u3002 I'm still studying. An adverb indicating that someone or something is still in a state they were previously in, often translated as \"still\" or \"(not) yet.\" \u301c\u307e\u3057\u3087\u3046 Grammar Point Sentence 1 \u65e5\u672c\u8a9e\u3092\u52c9\u5f37\u3057 \u307e\u3057\u3087\u3046 \u3002 Let's study Japanese. \u65e5\u672c\u8a9e\u3092\u52c9\u5f37\u3057 \u307e\u3057\u3087\u3046 \u304b\u3002 Shall we study Japanese? A formal volitional verb ending indicating the speaker's intent or invitation to do something. \u301c\u307e\u305b\u3093\u304b Grammar Point Sentence 1 \u65e5\u672c\u8a9e\u3092\u52c9\u5f37\u3057 \u307e\u305b\u3093\u304b \u3002 Would you like to study Japanese? 2 \u4e00\u7dd2\u306b\u52c9\u5f37\u3057 \u306a\u3044\uff1f Wanna study together? The formal negative question form of a verb can be used to extend an invitation formally. The informal non-past negative form of a verb can be used to extend an invitation informally. \u307e\u3067 Grammar Point Sentence 1 \u79c1\u306f\u4e94\u6642 \u307e\u3067 \u65e5\u672c\u8a9e\u3092\u52c9\u5f37\u3057\u307e\u3059\u3002 I will study Japanese until 5 o'clock. \u6771\u4eac \u307e\u3067 3 \u6642\u9593\u304b\u304b\u308a\u307e\u3059\u3002 It takes 3 hours until Tokyo. A grammar particle which indicates a spacial or temporal limit. \u3082\u3046 Grammar Point Sentence 1 \u3082\u3046 \u65e5\u672c\u8a9e\u3092\u52c9\u5f37\u3057\u307e\u3057\u305f\u304b\u3002 Have you already studied Japanese? \u3082\u3046 \u672c\u304c\u3042\u308a\u307e\u305b\u3093\u3002 I don't have the book anymore . An adverb indicating that someone or something is no longer in a state they were previously in, often translated as \"already\" or \"(not) any longer.\" \u3082\u3089\u3046 Grammar Point Sentence 1 \u53cb\u9054\u306f\u3053\u306e\u672c\u3092\u8cb7\u3063\u3066 \u3082\u3089\u3044\u307e\u3057\u305f \u3002 My friend bought me this book. \u53cb\u9054\u306b\u3053\u306e\u672c\u3092 \u3082\u3089\u3044\u307e\u3057\u305f \u3002 I received this book from my friend. An auxiliary verb indicating that the speaker or someone else receives something or some benefit from an action from someone else. The honorific form is \u3044\u305f\u3060\u304f. \u3088\u3046 Grammar Point Sentence 1 \u65e5\u672c\u8a9e\u3092\u52c9\u5f37\u3057 \u3088\u3046 \u3002 Let's study Japanese. \u5730\u7403\u3092\u5b88 \u308d\u3046 \u3002 Let's protect the Earth. An informal volitional verb ending indicating the speaker's intent or invitation to do something. \u3088\u3046\u3068\u304a\u3082\u3046 (\u3088\u3046\u3068\u601d\u3046) Grammar Point Sentence 1 \u65e5\u672c\u8a9e\u3092\u52c9\u5f37\u3057 \u3088\u3046\u3068\u601d\u3044\u307e\u3059 \u3002 I think I'll study Japanese. \u82f1\u8a9e\u3067\u8a71\u3059 \u307e\u3044\u3068\u601d\u3044\u307e\u3059 \u3002 I think I won't speak in English. A phrase indicating that the speaker desires to do something. The negative form is \u307e\u3044\u3068\u601d\u3046. \u3089\u308c\u308b Grammar Point Sentence 1 \u6f22\u5b57\u3092\u8aad \u3081\u308b \u3002 I can read kanji. \u523a\u8eab\u3092\u98df\u3079 \u3089\u308c\u307e\u3059 \u3002 I can eat sashimi. An auxiliary verb indicating the potential to do something. \u3092 Grammar Point Sentence 1 \u79c1\u306f\u65e5\u672c\u8a9e \u3092 \u52c9\u5f37\u3057\u307e\u3059\u3002 I study Japanese. 2 \u79c1\u306f\u516c\u5712 \u3092 \u6b69\u304d\u307e\u3057\u305f\u3002 I walked through the park. A grammar particle indicating a direct object. A grammar particle indicating a space through or along which someone or something moves.","title":"N5"},{"location":"japanese/grammar/n5/#n5-grammar","text":"","title":"N5 Grammar"},{"location":"japanese/grammar/n5/#_1","text":"Grammar Point Sentence 1 \u65e5\u672c\u8a9e\u3092\u6559\u3048\u3066 \u3042\u3052\u307e\u3059 \u3002 I will teach you Japanese. \u3053\u306e\u672c\u3092 \u3042\u3052\u307e\u3059 \u3002 I'll give you this book. An auxiliary verb indicating that the speaker gives something or some action to someone else. When speaking to someone of lower status, \u3042\u3052\u308b can be replaced with \u3084\u308b. The honorific form is \u3055\u3057\u3042\u3052\u308b.","title":"\u3042\u3052\u308b"},{"location":"japanese/grammar/n5/#_2","text":"Grammar Point Sentence 1 \u65e5\u672c\u8a9e\u3092\u52c9\u5f37\u3057\u305f \u5f8c\u3067 \u5bdd\u307e\u3057\u305f\u3002 I slept after studying Japanese. \u30af\u30e9\u30b9\u306e \u5f8c\u3067 \u5e30\u308a\u307e\u3057\u305f\u3002 I went home after class. A conjunction indicating that something takes place after something else.","title":"\u3042\u3068\u3067 (\u5f8c\u3067)"},{"location":"japanese/grammar/n5/#_3","text":"Grammar Point Sentence 1 \u79c1\u306f\u82f1\u8a9e \u304b \u65e5\u672c\u8a9e\u3092\u52c9\u5f37\u3057\u307e\u3059\u3002 I will study either English or Japanese. \u660e\u65e5\u6388\u696d\u304c\u3042\u308b \u304b \u306a\u3044 \u304b \u5206\u304b\u308a\u307e\u305b\u3093\u3002 I don't know whether there is class tomorrow or not. A grammar particle which indicates an alternative.","title":"\u304b"},{"location":"japanese/grammar/n5/#_4","text":"Grammar Point Sentence 1 \u305d\u306e\u6f22\u5b57\u306e\u66f8\u304d \u65b9 \u304c\u5206\u304b\u308a\u307e\u305b\u3093\u3002 I don't know how to write that kanji. A nominalizing suffix indicating a way of doing something.","title":"\u304b\u305f (\u65b9)"},{"location":"japanese/grammar/n5/#_5","text":"Grammar Point Sentence 1 \u6765\u5e74\u65e5\u672c\u3078\u884c\u304f \u304b\u3089 \u65e5\u672c\u8a9e\u3092\u52c9\u5f37\u3059\u308b\u3002 I'm studying Japanese because I'm going to Japan next year. \u9ad8\u304b\u3063\u305f \u304b\u3089 \u8cb7\u3044\u307e\u305b\u3093\u3067\u3057\u305f\u3002 I didn't buy it because it was expensive. 2 \u65e5\u672c\u8a9e\u3092\u52c9\u5f37\u3057\u3066 \u304b\u3089 \u5168\u90e8\u3092\u5fd8\u308c\u307e\u3057\u305f\u3002 After studying Japanese, I forgot everything. A conjunction indicating a reason or cause. A conjunction indicating after or since something takes place.","title":"\u304b\u3089"},{"location":"japanese/grammar/n5/#_6","text":"Grammar Point Sentence 1 \u767e\u4e94\u5341\u5186 \u304f\u3089\u3044 \u3067\u3057\u305f\u3002 It was about 150 yen. \u4e8c\u6642\u9593 \u304f\u3089\u3044 \u304b\u304b\u308a\u307e\u3059\u3002 It takes about 2 hours. A particle indicating an approximate quantity or otherwise translated as \"about.\" \u3050\u3089\u3044 has the same meaning.","title":"\u304f\u3089\u3044"},{"location":"japanese/grammar/n5/#_7","text":"Grammar Point Sentence 1 \u5f7c\u306f\u65e5\u672c\u8a9e\u3092\u6559\u3048\u3066 \u304f\u308c\u307e\u3057\u305f \u3002 He taught me Japanese. \u5f7c\u306f\u3053\u306e\u672c\u3092 \u304f\u308c\u307e\u3057\u305f \u3002 He gave me this book. An auxiliary verb indicating that someone gives something or does some action for someone else. The honorific form is \u304f\u3060\u3055\u308b.","title":"\u304f\u308c\u308b"},{"location":"japanese/grammar/n5/#_8","text":"Grammar Point Sentence 1 \u65e5\u672c\u8a9e\u3067\u66f8\u304f \u3053\u3068 \u306f\u96e3\u3057\u3002 It's difficult to write in Japanese. A nominalizer; it suggests the speaker is not as emotionally close to the concept compared to if the speaker had used \u306e.","title":"\u3053\u3068"},{"location":"japanese/grammar/n5/#_9","text":"Grammar Point Sentence 1 \u3053\u3093\u306a \u672c\u3092\u8cb7\u3044\u305f\u3044\u3067\u3059\u3002 I'd like to buy a book like this . \u305d\u3093\u306a \u3053\u3068\u3057\u306a\u3044\u3067\u3088\uff01 Don't do such a thing ! A word meaning \"such a thing\" or \"this sort of thing.\" It can be adjusted for proximity to the speaker (\u305d\u3093\u306a\u3001\u3042\u3093\u306a) or be made inquisitive (\u3069\u3093\u306a).","title":"\u3053\u3093\u306a"},{"location":"japanese/grammar/n5/#_10","text":"Grammar Point Sentence 1 \u305d\u3093\u306a\u306b \u96e3\u3057\u304b\u3063\u305f\uff1f Was it that difficult? \u3053\u3093\u306a\u306b \u7f8e\u5473\u3057\u3044\u3053\u3068\u8ab0\u3067\u3082\u597d\u304d\u3067\u3059\u3002 Anyone likes something delicious like this . A word meaning \"like this.\" It can be adjusted for proximity to the speaker ( \u305d\u3093\u306a\u306b\u3001\u3042\u3093\u306a\u306b).","title":"\u3053\u3093\u306a\u306b"},{"location":"japanese/grammar/n5/#_11","text":"Grammar Point Sentence 1 \u65e5\u672c\u8a9e\u306e\u96e3\u3057 \u3055 \u304c\u3088\u304f\u5206\u304b\u3063\u3066\u308b\u3002 I know the difficulty of Japanese. A nominalizing suffix attachable to the stem of adjectives.","title":"\u3055"},{"location":"japanese/grammar/n5/#_12","text":"Grammar Point Sentence 1 \u65e5\u672c\u8a9e \u3057\u304b \u52c9\u5f37\u3057\u307e\u305b\u3093\u3002 I study only Japanese. A particle indicating that something S and only S is the case, often translated as \"nothing,\" \"nobody,\" or \"only.\"","title":"\u3057\u304b"},{"location":"japanese/grammar/n5/#_13","text":"Grammar Point Sentence 1 \u671d\u8d77\u304d\u3066 \u3059\u3050 \u306b\u65e5\u672c\u8a9e\u3092\u52c9\u5f37\u3057\u307e\u3059\u3002 As soon as I wake up, I study Japanese. \u5b66\u6821\u306f\u99c5\u306e \u3059\u3050 \u524d\u3067\u3059\u3002 The school is right in front of the station. An adverb indicating not much temporal or physical distance, often translated as \"as soon as,\" \"immediately,\" \"right.\"","title":"\u3059\u3050"},{"location":"japanese/grammar/n5/#_14","text":"Grammar Point Sentence 1 \u79c1\u306f\u65e5\u672c\u8a9e\u3092\u52c9\u5f37\u3057 \u305f\u3044 \u3067\u3059\u3002 I want to study Japanese. \u79c1\u306f\u523a\u8eab\u3092\u98df\u3079 \u305f\u3044 \u3067\u3059\u3002 I want to eat sashimi. An auxiliary adjective indicating the desire to do something.","title":"\u305f\u3044"},{"location":"japanese/grammar/n5/#_15","text":"Grammar Point Sentence 1 \u65e5\u672c\u8a9e\u304c\u52c9\u5f37\u3057\u305f \u3060\u3051 \u3067\u3059\u3002 I just studied (and did nothing else with) Japanese. \u79c1 \u3060\u3051 \u65e5\u672c\u8a9e\u3092\u8a71\u305b\u307e\u3059\u3002 Only I can speak Japanese. A particle expressing a limit on something, often translated as \"just,\" \"merely,\" \"only,\" or \"that's all.\"","title":"\u3060\u3051"},{"location":"japanese/grammar/n5/#_16","text":"See \u3067\u3057\u3087\u3046.","title":"\u3060\u308d\u3046"},{"location":"japanese/grammar/n5/#_17","text":"Grammar Point Sentence 1 \u8a66\u9a13\u306e \u305f\u3081 \u306b\u52c9\u5f37\u3057\u307e\u3059\u3002 I'm studying in preparation for exams. \u65e5\u672c\u8a9e\u3092\u52c9\u5f37\u3059\u308b \u305f\u3081 \u306b\u65e5\u672c\u306b\u884c\u304d\u307e\u3059\u3002 I'm going to Japan in order to study Japanese. \u75c5\u6c17\u306b\u306a\u3063\u305f \u305f\u3081 \u3001\u30af\u30e9\u30b9\u306b\u884c\u304b\u306a\u304b\u3063\u305f\u3002 Because I got sick, I didn't go to class. A noun expressing a purpose, reason, or cause.","title":"\u305f\u3081"},{"location":"japanese/grammar/n5/#_18","text":"Grammar Point Sentence 1 \u5f7c\u5973\u306f\u65e5\u672c\u8a9e\u3092\u52c9\u5f37\u3059\u308b \u3063\u3066 \u8a00\u3063\u305f\u3002 She said she studies Japanese. \u79c1\u306f\u65e5\u672c\u8a9e\u3092\u52c9\u5f37\u3057\u3088\u3046\u304b \u3063\u3066 \u601d\u3044\u307e\u3059\u3002 I wonder if I should study Japanese. A colloquial particle indicating a quotation.","title":"\u3063\u3066"},{"location":"japanese/grammar/n5/#_19","text":"Grammar Point Sentence 1 \u79c1\u306f\u65e5\u672c\u3078\u884c\u3063 \u3066 \u52c9\u5f37\u3057\u307e\u3057\u305f\u3002 I went to Japan and studied. \u3053\u308c\u306f\u9ad8\u304f \u3066 \u7f8e\u5473\u3057\u3044\u3002 This is expensive and delicious. \u5f7c\u306f\u5148\u751f \u3067 \u512a\u3057\u3044\u3002 He is a teacher, and he is nice. A verb or i-adjective ending indicating \"and.\" For na-adjectives and nouns, \u3066 becomes \u3067 instead.","title":"\u3066"},{"location":"japanese/grammar/n5/#_20","text":"Grammar Point Sentence 1 \u65e5\u672c\u4eba\u306f\u306f\u3057 \u3067 \u98df\u3079\u307e\u3059\u3002 Japanese people eat with chopsticks. \u3053\u308c\u306f\u65e5\u672c\u8a9e \u3067 \u4f55\u3067\u3059\u304b\u3002 What is this in Japanese? A grammar particle which indicates the use of something for doing something.","title":"\u3067"},{"location":"japanese/grammar/n5/#_21","text":"Grammar Point Sentence 1 \u5f7c\u306f\u65e5\u672c\u8a9e\u3067\u8a71\u3059 \u3067\u3057\u3087\u3046 \u3002 He will probably speak in Japanese. \u3053\u306e\u672c\u306f\u9ad8\u3044 \u3060\u308d\u3046 \u3002 This book is probably expensive. An auxiliary indicating conjecture grounded in no substantial evidence. \u3060\u308d \u3046 is the informal form.","title":"\u3067\u3057\u3087\u3046"},{"location":"japanese/grammar/n5/#_22","text":"Grammar Point Sentence 1 \u65e5\u672c\u8a9e \u3067\u3082 \u8a71\u305b\u307e\u3059\u3002 I can speak even Japanese. \u5b50\u4f9b \u3067\u3082 \u305d\u306e\u3053\u3068\u3092\u3067\u304d\u307e\u3059\u3002 Even a child can do that. A particle meaning \"even.\"","title":"\u3067\u3082"},{"location":"japanese/grammar/n5/#_23","text":"Grammar Point Sentence 1 \u79c1\u306f\u3042\u306a\u305f \u3068 \u65e5\u672c\u8a9e\u3092\u52c9\u5f37\u3057\u307e\u3059\u3002 I study Japanese with you. \u79c1\u306f\u65e5\u672c\u4eba \u3068 \u7d50\u5a5a\u3057\u307e\u3057\u305f\u3002 I (got) married ( to ) a Japanese person. A grammar particle indicating a reciprocal relationship with the subject.","title":"\u3068"},{"location":"japanese/grammar/n5/#_24","text":"Grammar Point Sentence 1 \u65e5\u672c\u8a9e\u3067 \u3069\u3046 \u8a00\u3044\u307e\u3059\u304b\u3002 How do you say it in Japanese? \u672c\u306f \u3069\u3046 \u3067\u3057\u305f\u304b\u3002 How was the book? A grammar particle which asks about the state of something or someone or the way of doing something.","title":"\u3069\u3046"},{"location":"japanese/grammar/n5/#_25","text":"Grammar Point Sentence 1 \u3053\u306e\u672c\u306f\u305d\u306e\u672c \u3068\u540c\u3058\u304f\u3089\u3044 \u9762\u767d\u3044\u3002 This book is as interesting as that one. A phrase indicating that one thing is as \u301c as another.","title":"\u3068\u540c\u3058\u304f\u3089\u3044\u301c"},{"location":"japanese/grammar/n5/#_26","text":"Grammar Point Sentence 1 \u65e5\u672c\u8a9e\u3092\u52c9\u5f37\u3059\u308b \u6642 \u672c\u3092\u305f\u304f\u3055\u3093\u8aad\u307f\u307e\u3059\u3002 When I study Japanese I read a lot of books. \u9759\u304b\u306a \u6642 \u52c9\u5f37\u3067\u304d\u307e\u3059\u3002 I'm able to study when it's quiet. A dependent noun indicating a time when someone or something did or does something.","title":"\u3068\u304d"},{"location":"japanese/grammar/n5/#_27","text":"Grammar Point Sentence 1 \u65e5\u672c\u8a9e\u3068\u82f1\u8a9e\u3068\u3001 \u3069\u3061\u3089 \u304c\u9762\u767d\u3044\uff1f Between Japanese and English, which is more interesting? A word meaning \"which,\" among a group of things, particularly two.","title":"\u3069\u3061\u3089"},{"location":"japanese/grammar/n5/#_28","text":"Grammar Point Sentence 1 \u9ec4\u8272\u3068\u7d2b\u8272\u3068\u9752\u8272\u3067\u3001 \u3069\u308c \u304c\u4e00\u756a\u7f8e\u3057\u3044\u3067\u3059\u304b\u3002 Between yellow, purple, and blue, which is the most beautiful? A word meaning \"which,\" among a group of 3 or more.","title":"\u3069\u308c"},{"location":"japanese/grammar/n5/#_29","text":"Grammar Point Sentence 1 \u52c9\u5f37\u3057 \u306a\u3044\u3067 \u5b66\u6821\u3078\u6765\u307e\u3057\u305f\u3002 I came to school without studying. A negative te-form indicating not doing something or without doing something.","title":"\u306a\u3044\u3067"},{"location":"japanese/grammar/n5/#_30","text":"Grammar Point Sentence 1 \u65e5\u672c\u8a9e\u3092\u52c9\u5f37\u3057 \u306a\u3055\u3044 \u3002 Study Japanese. An auxiliary verb which creates an imperative.","title":"\u306a\u3055\u3044"},{"location":"japanese/grammar/n5/#_31","text":"Grammar Point Sentence 1 \u672c\u3092\u8aad\u307f \u306a\u304c\u3089 \u5b66\u6821\u3078\u6b69\u304d\u307e\u3057\u305f\u3002 I walked to school while reading a book. A conjunction indicating the surrounding clauses happen simultaneously, often translated as \"while\" or \"with.\"","title":"\u306a\u304c\u3089"},{"location":"japanese/grammar/n5/#_32","text":"Grammar Point Sentence 1 \u3042\u306a\u305f\u306e\u65e5\u672c\u8a9e\u304c\u4e0a\u624b\u306b \u306a\u308a\u307e\u3057\u305f \u3002 You've become good at Japanese. \u5bd2\u304f \u306a\u308a\u307e\u3057\u305f \u3002 It's become cold. A word meaning \"to become\" or \"come to be.\"","title":"\u306a\u308b"},{"location":"japanese/grammar/n5/#_33","text":"Grammar Point Sentence 1 \u65e5\u672c\u8a9e\u3092\u52c9\u5f37\uff08\u3057\uff09 \u306b \u5b66\u6821\u3078\u884c\u304d\u307e\u3059\u3002 I'm going to school (in order) to study Japanese. \u672c\u3092\u8cb7\u3044 \u306b \u6765\u307e\u3057\u305f\u3002 I came (in order) to buy a book. A particle indicating the purpose of movement. This construct is only used with motion verbs like \u884c\u304f, \u6765\u308b, \u5e30\u308b, \u5165\u308b, and \u51fa\u308b.","title":"\u306b"},{"location":"japanese/grammar/n5/#_34","text":"Grammar Point Sentence 1 \u672c\u306f\u65e5\u672c\u8a9e \u306e \u3092\u8cb7\u3044\u307e\u3057\u305f\u3002 As for books, I bought a Japanese one . \u3042\u306e\u672c\u306f\u30c8\u30e0 \u306e \u3067\u3059\u3002 That book is Tom's book . 2 \u3069\u3046\u3057\u3066\u52c9\u5f37\u3057\u3066\u3044\u308b \u306e \uff1f Why are you studying ( you've got to tell me )? \u660e\u65e5\u30c6\u30b9\u30c8\u304c\u3042\u308b \u306e \u3002 Because there's a test tomorrow. 3 \u52c9\u5f37\u3059\u308b \u306e \u306f\u96e3\u3057\u3044\u3002 Studying is difficult. \u5f7c\u304c\u65e5\u672c\u8a9e\u3092\u8a71\u3059 \u306e \u3092\u805e\u304d\u307e\u3057\u305f\u3002 I heard him speaking Japanese. A dependent, indefinite pronoun indicating \"one\" or \"_'s.\" An informal sentence-final particle indicating an explanation or asking for an explanation, used by children or female speakers. If male speakers use it, it is only for questions. A clause nominalizer.","title":"\u306e"},{"location":"japanese/grammar/n5/#_35","text":"Grammar Point Sentence 1 \u4f55\u3092\u3057\u3066\u3044\u308b \u3093\u3067\u3059 \u304b\u3002 What are you doing ( you've got to tell me )? \u65e5\u672c\u8a9e\u3092\u52c9\u5f37\u3057\u3066\u3044\u308b \u306e\u3067\u3059 \u3002 ( The explanation is that ) I'm studying Japanese. A sentence-ending phrase indicating an explanation or asking for an explanation. An informal form is \u3093\u3067\u3059.","title":"\u306e\u3067\u3059"},{"location":"japanese/grammar/n5/#_36","text":"Grammar Point Sentence 1 \u65e5\u672c\u8a9e \u3070\u304b\u308a \u52c9\u5f37\u3057\u3066\u3044\u307e\u3059\u3002 I'm studying only Japanese. \u79c1\u306f\u52c9\u5f37\u3057\u305f \u3070\u304b\u308a \u3067\u3059\u3002 I studied and haven't done anything else . A particle indicating that something is the only state, thing, or action.","title":"\u3070\u304b\u308a"},{"location":"japanese/grammar/n5/#_37","text":"Grammar Point Sentence 1 \u3042\u306a\u305f\u306e\u672c\u306f\u3069\u3063\u3061\u3067\u3059\u304b\u3002 Which book is yours? \u5927\u304d\u3044 \u307b\u3046 \u3067\u3059\u3002 The bigger one. \u597d\u304d\u306a \u307b\u3046 \u3092\u53d6\u3063\u3066\u304f\u3060\u3055\u3044\u3002 Please take the one you like most . A word indicating more than or greater in a comparison. It comes from the form \u307b\u3046\u304c\u301c\u3088\u308a.","title":"\u307b\u3046"},{"location":"japanese/grammar/n5/#_38","text":"Grammar Point Sentence 1 \u65e5\u672c\u8a9e\u306e \u307b\u3046\u304c \u82f1\u8a9e \u3088\u308a \u9762\u767d\u3044\u3002 Japanese is more interesting than English. \u904a\u3076 \u307b\u3046\u304c \u52c9\u5f37\u3059\u308b \u3088\u308a \u697d\u3057\u3044\u3002 Playing is more fun than studying. A phrase for comparing two things, where one is more or greater than the other.","title":"\u307b\u3046\u304c\u301c\u3088\u308a"},{"location":"japanese/grammar/n5/#_39","text":"Grammar Point Sentence 1 \u82f1\u8a9e\u306f\u65e5\u672c\u8a9e \u307b\u3069 \u9762\u767d\u304f\u306a\u3044\u3002 English is not as interesting as Japanese. A particle indicating an extent or degree, often translated as \"[not] as ~ as ~.\"","title":"\u307b\u3069"},{"location":"japanese/grammar/n5/#_40","text":"Grammar Point Sentence 1 \u5bdd\u308b \u524d\u306b \u65e5\u672c\u8a9e\u3092\u52c9\u5f37\u3057\u307e\u3059\u3002 I study Japanese before I sleep. \u30c6\u30b9\u30c8\u306e \u524d\u306b \u52c9\u5f37\u3057\u307e\u3059\u3002 I'll study before the test. A conjunction indicating in front of or before something occurs.","title":"\u307e\u3048\u306b (\u524d\u306b)"},{"location":"japanese/grammar/n5/#_41","text":"Grammar Point Sentence 1 \u307e\u3060 \u65e5\u672c\u8a9e\u3092\u5206\u304b\u308a\u307e\u305b\u3093\u3002 I still don't understand Japanese. \u79c1\u306f \u307e\u3060 \u52c9\u5f37\u3057\u3066\u3044\u307e\u3059\u3002 I'm still studying. An adverb indicating that someone or something is still in a state they were previously in, often translated as \"still\" or \"(not) yet.\"","title":"\u307e\u3060"},{"location":"japanese/grammar/n5/#_42","text":"Grammar Point Sentence 1 \u65e5\u672c\u8a9e\u3092\u52c9\u5f37\u3057 \u307e\u3057\u3087\u3046 \u3002 Let's study Japanese. \u65e5\u672c\u8a9e\u3092\u52c9\u5f37\u3057 \u307e\u3057\u3087\u3046 \u304b\u3002 Shall we study Japanese? A formal volitional verb ending indicating the speaker's intent or invitation to do something.","title":"\u301c\u307e\u3057\u3087\u3046"},{"location":"japanese/grammar/n5/#_43","text":"Grammar Point Sentence 1 \u65e5\u672c\u8a9e\u3092\u52c9\u5f37\u3057 \u307e\u305b\u3093\u304b \u3002 Would you like to study Japanese? 2 \u4e00\u7dd2\u306b\u52c9\u5f37\u3057 \u306a\u3044\uff1f Wanna study together? The formal negative question form of a verb can be used to extend an invitation formally. The informal non-past negative form of a verb can be used to extend an invitation informally.","title":"\u301c\u307e\u305b\u3093\u304b"},{"location":"japanese/grammar/n5/#_44","text":"Grammar Point Sentence 1 \u79c1\u306f\u4e94\u6642 \u307e\u3067 \u65e5\u672c\u8a9e\u3092\u52c9\u5f37\u3057\u307e\u3059\u3002 I will study Japanese until 5 o'clock. \u6771\u4eac \u307e\u3067 3 \u6642\u9593\u304b\u304b\u308a\u307e\u3059\u3002 It takes 3 hours until Tokyo. A grammar particle which indicates a spacial or temporal limit.","title":"\u307e\u3067"},{"location":"japanese/grammar/n5/#_45","text":"Grammar Point Sentence 1 \u3082\u3046 \u65e5\u672c\u8a9e\u3092\u52c9\u5f37\u3057\u307e\u3057\u305f\u304b\u3002 Have you already studied Japanese? \u3082\u3046 \u672c\u304c\u3042\u308a\u307e\u305b\u3093\u3002 I don't have the book anymore . An adverb indicating that someone or something is no longer in a state they were previously in, often translated as \"already\" or \"(not) any longer.\"","title":"\u3082\u3046"},{"location":"japanese/grammar/n5/#_46","text":"Grammar Point Sentence 1 \u53cb\u9054\u306f\u3053\u306e\u672c\u3092\u8cb7\u3063\u3066 \u3082\u3089\u3044\u307e\u3057\u305f \u3002 My friend bought me this book. \u53cb\u9054\u306b\u3053\u306e\u672c\u3092 \u3082\u3089\u3044\u307e\u3057\u305f \u3002 I received this book from my friend. An auxiliary verb indicating that the speaker or someone else receives something or some benefit from an action from someone else. The honorific form is \u3044\u305f\u3060\u304f.","title":"\u3082\u3089\u3046"},{"location":"japanese/grammar/n5/#_47","text":"Grammar Point Sentence 1 \u65e5\u672c\u8a9e\u3092\u52c9\u5f37\u3057 \u3088\u3046 \u3002 Let's study Japanese. \u5730\u7403\u3092\u5b88 \u308d\u3046 \u3002 Let's protect the Earth. An informal volitional verb ending indicating the speaker's intent or invitation to do something.","title":"\u3088\u3046"},{"location":"japanese/grammar/n5/#_48","text":"Grammar Point Sentence 1 \u65e5\u672c\u8a9e\u3092\u52c9\u5f37\u3057 \u3088\u3046\u3068\u601d\u3044\u307e\u3059 \u3002 I think I'll study Japanese. \u82f1\u8a9e\u3067\u8a71\u3059 \u307e\u3044\u3068\u601d\u3044\u307e\u3059 \u3002 I think I won't speak in English. A phrase indicating that the speaker desires to do something. The negative form is \u307e\u3044\u3068\u601d\u3046.","title":"\u3088\u3046\u3068\u304a\u3082\u3046 (\u3088\u3046\u3068\u601d\u3046)"},{"location":"japanese/grammar/n5/#_49","text":"Grammar Point Sentence 1 \u6f22\u5b57\u3092\u8aad \u3081\u308b \u3002 I can read kanji. \u523a\u8eab\u3092\u98df\u3079 \u3089\u308c\u307e\u3059 \u3002 I can eat sashimi. An auxiliary verb indicating the potential to do something.","title":"\u3089\u308c\u308b"},{"location":"japanese/grammar/n5/#_50","text":"Grammar Point Sentence 1 \u79c1\u306f\u65e5\u672c\u8a9e \u3092 \u52c9\u5f37\u3057\u307e\u3059\u3002 I study Japanese. 2 \u79c1\u306f\u516c\u5712 \u3092 \u6b69\u304d\u307e\u3057\u305f\u3002 I walked through the park. A grammar particle indicating a direct object. A grammar particle indicating a space through or along which someone or something moves.","title":"\u3092"}]}